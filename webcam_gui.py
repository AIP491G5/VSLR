import cv2
import torch
import numpy as np
import sys
import os
import warnings
import logging
import tkinter as tk
from tkinter import ttk
from PIL import Image, ImageTk
import time

# --- B·∫ÆT ƒê·∫¶U PH·∫¶N T√çCH H·ª¢P T·ª™ FILE inference.py ---

# C·∫•u h√¨nh m√¥i tr∆∞·ªùng (gi·ªØ nguy√™n t·ª´ file c·ªßa b·∫°n)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
warnings.filterwarnings("ignore")
logging.getLogger('tensorflow').disabled = True
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# Import c√°c module c·ªßa b·∫°n
from configs.config import Config
from src.utils.detector import MediaPipeProcessor
from src.models.model_utils import create_model, create_adjacency_matrix
from src.utils.data_utils import load_labels_from_csv
from src.utils.interpolate import interpolate_frames

class SignLanguageApp:
    def __init__(self, window_title="Sign Language Recognition"):
        """Kh·ªüi t·∫°o ·ª©ng d·ª•ng"""
        self.window = tk.Tk()
        self.window.title(window_title)
        self.window.protocol("WM_DELETE_WINDOW", self.on_closing)

        # --- C√°c bi·∫øn tr·∫°ng th√°i c·ªßa ·ª©ng d·ª•ng ---
        self.cap = None
        self.is_camera_on = False
        self.is_recording = False
        self.show_skeleton = True
        self.keypoints_sequence = []
        self.recording_start_time = None
        self.last_prediction = ""
        self.last_confidence = 0.0

        # --- T·∫£i Model v√† c√°c th√†nh ph·∫ßn x·ª≠ l√Ω ---
        print("üîÑ ƒêang t·∫£i model v√† c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt...")
        self.config = Config()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # T·∫£i nh√£n
        _, _, _, self.id_to_label_mapping = load_labels_from_csv(None, self.config)
        num_classes = len(self.id_to_label_mapping)
        
        # T·∫°o v√† t·∫£i model
        A = create_adjacency_matrix(self.config)
        self.model = create_model(self.config, A, num_classes=num_classes, device=self.device)
        model_path = 'outputs/models/best_hgc_lstm.pth' # ƒê∆∞·ªùng d·∫´n model c·ªßa b·∫°n
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.eval()
        
        # Kh·ªüi t·∫°o b·ªô x·ª≠ l√Ω MediaPipe
        self.processor = MediaPipeProcessor(self.config)
        print("‚úÖ Model ƒë√£ t·∫£i xong!")

        # --- Thi·∫øt l·∫≠p giao di·ªán ---
        self.create_widgets()

        # B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p c·∫≠p nh·∫≠t frame
        self.update_frame()

    def create_widgets(self):
        """T·∫°o c√°c th√†nh ph·∫ßn tr√™n giao di·ªán"""
        # --- Khung ch√≠nh ---
        main_frame = ttk.Frame(self.window, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))

        # --- Khung Video ---
        video_frame = ttk.LabelFrame(main_frame, text="Webcam Feed")
        video_frame.grid(row=0, column=0, padx=5, pady=5, sticky=(tk.W, tk.E, tk.N, tk.S))
        self.canvas = tk.Canvas(video_frame, width=self.config.data.width, height=self.config.data.height)
        self.canvas.pack()

        # --- Khung ƒêi·ªÅu khi·ªÉn ---
        control_frame = ttk.LabelFrame(main_frame, text="B·∫£ng ƒëi·ªÅu khi·ªÉn")
        control_frame.grid(row=1, column=0, padx=5, pady=5, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        self.btn_toggle_cam = ttk.Button(control_frame, text="B·∫≠t Camera", command=self.toggle_camera)
        self.btn_toggle_cam.grid(row=0, column=0, padx=5, pady=5, sticky="ew")

        self.btn_toggle_skeleton = ttk.Button(control_frame, text="T·∫Øt Khung x∆∞∆°ng", command=self.toggle_skeleton)
        self.btn_toggle_skeleton.grid(row=0, column=1, padx=5, pady=5, sticky="ew")

        self.btn_toggle_record = ttk.Button(control_frame, text="B·∫Øt ƒë·∫ßu Ghi", command=self.toggle_recording)
        self.btn_toggle_record.grid(row=1, column=0, padx=5, pady=5, sticky="ew")

        self.btn_predict = ttk.Button(control_frame, text="B·∫Øt ƒë·∫ßu D·ª± ƒëo√°n", command=self.run_prediction)
        self.btn_predict.grid(row=1, column=1, padx=5, pady=5, sticky="ew")

        # --- Khung Th√¥ng tin ---
        info_frame = ttk.LabelFrame(main_frame, text="Th√¥ng tin")
        info_frame.grid(row=0, column=1, rowspan=2, padx=5, pady=5, sticky=(tk.W, tk.E, tk.N, tk.S))

        ttk.Label(info_frame, text="Tr·∫°ng th√°i:", font=("Helvetica", 12, "bold")).pack(anchor="w", padx=5, pady=(5,0))
        self.lbl_status = ttk.Label(info_frame, text="S·∫µn s√†ng", foreground="blue", font=("Helvetica", 11))
        self.lbl_status.pack(anchor="w", padx=5, pady=(0,10))

        ttk.Label(info_frame, text="Th·ªùi gian ghi h√¨nh:", font=("Helvetica", 12, "bold")).pack(anchor="w", padx=5, pady=(5,0))
        self.lbl_timer = ttk.Label(info_frame, text="0.0 gi√¢y", font=("Helvetica", 11))
        self.lbl_timer.pack(anchor="w", padx=5, pady=(0,10))

        ttk.Label(info_frame, text="K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN:", font=("Helvetica", 14, "bold"), foreground="green").pack(anchor="w", padx=5, pady=(15,0))
        self.lbl_prediction_result = ttk.Label(info_frame, text="---", font=("Helvetica", 16, "bold"))
        self.lbl_prediction_result.pack(anchor="w", padx=5, pady=(0,5))
        
        self.lbl_confidence = ttk.Label(info_frame, text="ƒê·ªô tin c·∫≠y: 0.0%", font=("Helvetica", 11))
        self.lbl_confidence.pack(anchor="w", padx=5, pady=(0,10))

    def update_frame(self):
        """V√≤ng l·∫∑p ch√≠nh ƒë·ªÉ c·∫≠p nh·∫≠t frame t·ª´ camera v√† hi·ªÉn th·ªã"""
        display_frame = None

        if self.is_camera_on and self.cap.isOpened():
            ret, frame = self.cap.read()
            if ret:
                frame = cv2.flip(frame, 1) # L·∫≠t frame cho gi·ªëng g∆∞∆°ng
                
                # 1. X·ª≠ l√Ω frame ƒë·ªÉ l·∫•y t·ªça ƒë·ªô keypoints (kh√¥ng v·∫Ω)
                #    H√†m n√†y tr·∫£ v·ªÅ (khung h√¨nh g·ªëc, k·∫øt qu·∫£ landmarks)
                original_frame, res = self.processor.process_frame(frame)

                # 2. Quy·∫øt ƒë·ªãnh xem c√≥ v·∫Ω khung x∆∞∆°ng hay kh√¥ng
                if self.show_skeleton:
                    # N·∫øu B·∫¨T, g·ªçi h√†m draw_landmarks chuy√™n d·ª•ng c·ªßa b·∫°n
                    display_frame = self.processor.draw_landmarks(original_frame, res)
                else:
                    # N·∫øu T·∫ÆT, ch·ªâ s·ª≠ d·ª•ng khung h√¨nh g·ªëc
                    display_frame = original_frame

                # 3. Ghi l·∫°i keypoints n·∫øu ƒëang trong ch·∫ø ƒë·ªô quay (logic n√†y kh√¥ng ƒë·ªïi)
                if self.is_recording:
                    keypoints = self.processor.extract_keypoints(res)
                    if keypoints is not None:
                        self.keypoints_sequence.append(keypoints)
                    
                    elapsed_time = time.time() - self.recording_start_time
                    self.lbl_timer.config(text=f"{elapsed_time:.1f} gi√¢y")
        
        # --- Hi·ªÉn th·ªã frame l√™n giao di·ªán ---
        # N·∫øu c√≥ frame ƒë·ªÉ hi·ªÉn th·ªã
        if display_frame is not None:
            # Chuy·ªÉn m√†u t·ª´ BGR (OpenCV) sang RGB (Tkinter) ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng
            frame_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            self.photo = ImageTk.PhotoImage(image=Image.fromarray(frame_rgb))
            self.canvas.create_image(0, 0, image=self.photo, anchor=tk.NW)
        # N·∫øu camera t·∫Øt, hi·ªÉn th·ªã khung h√¨nh ƒëen
        else:
             blank_frame = np.zeros((self.config.data.height, self.config.data.width, 3), dtype=np.uint8)
             self.photo = ImageTk.PhotoImage(image=Image.fromarray(blank_frame))
             self.canvas.create_image(0, 0, image=self.photo, anchor=tk.NW)

        # L√™n l·ªãch cho l·∫ßn c·∫≠p nh·∫≠t ti·∫øp theo
        self.window.after(15, self.update_frame)

    def toggle_camera(self):
        """B·∫≠t ho·∫∑c t·∫Øt camera"""
        if self.is_camera_on:
            self.is_camera_on = False
            self.btn_toggle_cam.config(text="B·∫≠t Camera")
            if self.cap:
                self.cap.release()
            self.lbl_status.config(text="Camera ƒë√£ t·∫Øt", foreground="red")
        else:
            self.cap = cv2.VideoCapture(0)
            
            # === B·∫ÆT ƒê·∫¶U PH·∫¶N TH√äM M·ªöI ===
            # Y√™u c·∫ßu webcam s·ª≠ d·ª•ng ƒë·ªô ph√¢n gi·∫£i v√† FPS t·ª´ config
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.config.data.width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.config.data.height)
            self.cap.set(cv2.CAP_PROP_FPS, self.config.data.video_fps)
            # === K·∫æT TH√öC PH·∫¶N TH√äM M·ªöI ===

            if self.cap.isOpened():
                self.is_camera_on = True
                self.btn_toggle_cam.config(text="T·∫Øt Camera")
                self.lbl_status.config(text="Camera ƒëang b·∫≠t", foreground="green")
            else:
                self.lbl_status.config(text="L·ªói: Kh√¥ng th·ªÉ m·ªü camera", foreground="red")

    def toggle_skeleton(self):
        """B·∫≠t ho·∫∑c t·∫Øt hi·ªÉn th·ªã khung x∆∞∆°ng"""
        self.show_skeleton = not self.show_skeleton
        text = "T·∫Øt Khung x∆∞∆°ng" if self.show_skeleton else "B·∫≠t Khung x∆∞∆°ng"
        self.btn_toggle_skeleton.config(text=text)

    def toggle_recording(self):
        """B·∫Øt ƒë·∫ßu ho·∫∑c k·∫øt th√∫c vi·ªác ghi h√¨nh"""
        if self.is_recording:
            # D·ª´ng ghi
            self.is_recording = False
            self.btn_toggle_record.config(text="B·∫Øt ƒë·∫ßu Ghi")
            self.lbl_status.config(text=f"ƒê√£ ghi xong {len(self.keypoints_sequence)} frames.", foreground="blue")
        else:
            # B·∫Øt ƒë·∫ßu ghi
            if not self.is_camera_on:
                self.lbl_status.config(text="L·ªói: Vui l√≤ng b·∫≠t camera tr∆∞·ªõc", foreground="red")
                return
            
            self.is_recording = True
            self.btn_toggle_record.config(text="K·∫øt th√∫c Ghi")
            self.keypoints_sequence = [] # X√≥a sequence c≈©
            self.recording_start_time = time.time()
            self.lbl_status.config(text="...ƒêang ghi...", foreground="orange")
            # X√≥a k·∫øt qu·∫£ d·ª± ƒëo√°n c≈©
            self.lbl_prediction_result.config(text="---")
            self.lbl_confidence.config(text="ƒê·ªô tin c·∫≠y: 0.0%")

    def run_prediction(self):
        """Ch·∫°y d·ª± ƒëo√°n tr√™n chu·ªói keypoints ƒë√£ ghi"""
        if self.is_recording:
            self.lbl_status.config(text="L·ªói: Vui l√≤ng d·ª´ng ghi h√¨nh tr∆∞·ªõc", foreground="red")
            return
            
        if not self.keypoints_sequence:
            self.lbl_status.config(text="L·ªói: Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n", foreground="red")
            return
        
        self.lbl_status.config(text="ƒêang x·ª≠ l√Ω v√† d·ª± ƒëo√°n...", foreground="purple")
        
        # N·ªôi suy frame ƒë·ªÉ kh·ªõp v·ªõi ƒë·∫ßu v√†o c·ªßa model
        input_data = interpolate_frames(self.keypoints_sequence, self.config.hgc_lstm.sequence_length)
        input_data = torch.tensor(input_data, dtype=torch.float32).unsqueeze(0).to(self.device)
        
        prediction = None
        label = "Unknown"
        confidence = 0.0

        with torch.no_grad():
            output = self.model(input_data)
            probs = torch.softmax(output, dim=1)
            max_prob, pred_idx = torch.max(probs, dim=1)
            
            confidence = max_prob.item()
            prediction = pred_idx.item()
            label = self.id_to_label_mapping.get(prediction + 1, "Unknown")

        # C·∫≠p nh·∫≠t giao di·ªán v·ªõi k·∫øt qu·∫£
        self.lbl_prediction_result.config(text=f"{label.upper()}")
        self.lbl_confidence.config(text=f"ƒê·ªô tin c·∫≠y: {confidence:.2%}")
        self.lbl_status.config(text="D·ª± ƒëo√°n ho√†n t·∫•t!", foreground="green")

    def on_closing(self):
        """X·ª≠ l√Ω khi ƒë√≥ng c·ª≠a s·ªï ·ª©ng d·ª•ng"""
        print("ƒêang ƒë√≥ng ·ª©ng d·ª•ng...")
        if self.cap:
            self.cap.release()
        self.window.destroy()

if __name__ == "__main__":
    # Kh·ªüi ch·∫°y ·ª©ng d·ª•ng
    app = SignLanguageApp()
    app.window.mainloop()