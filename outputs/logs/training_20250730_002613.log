2025-07-30 00:26:13,332 - INFO - ================================================================================
2025-07-30 00:26:13,332 - INFO - üöÄ VSLR Training Started
2025-07-30 00:26:13,332 - INFO - ================================================================================
2025-07-30 00:26:13,332 - INFO - üìù Log file: /home/na/VSLR/outputs/logs/training_20250730_002613.log
2025-07-30 00:26:13,332 - INFO - üìÖ Start time: 2025-07-30 00:26:13
2025-07-30 00:26:13,401 - INFO - Using device: cuda
2025-07-30 00:26:13,401 - INFO - Configuration loaded
2025-07-30 00:26:13,401 - INFO - Loading labels...
2025-07-30 00:26:13,407 - INFO - 
2025-07-30 00:26:13,407 - INFO -  Creating datasets...
2025-07-30 00:26:13,407 - INFO - Configuration:
2025-07-30 00:26:13,407 - INFO -    Split strategy: Stratified
2025-07-30 00:26:13,407 - INFO -    Train augmentations: ['translation', 'scaling']
2025-07-30 00:26:13,407 - INFO -    Val augmentations: None (for fair evaluation)
2025-07-30 00:26:13,407 - INFO -    Translation range: ¬±0.1
2025-07-30 00:26:13,407 - INFO -    Scale range: ¬±0.1
2025-07-30 00:26:13,408 - INFO -  Using stratified split strategy
2025-07-30 00:26:13,409 - INFO -  TRAIN dataset: 270 original files
2025-07-30 00:26:13,409 - INFO -  Augmentation enabled: 1080 total samples (x4)
2025-07-30 00:26:13,409 - INFO -   - Augmentations: ['translation', 'scaling']
2025-07-30 00:26:13,409 - INFO -   - Total combinations: 4
2025-07-30 00:26:13,409 - INFO -   - Combinations: ['original', 'translation', 'scaling', 'translation+scaling']
2025-07-30 00:26:13,409 - INFO -  TRAIN class distribution:
2025-07-30 00:26:13,409 - INFO -   Class 1: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 2: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 3: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 4: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 5: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 6: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 7: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 8: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 9: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 10: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 11: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 12: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 13: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 14: 18 samples
2025-07-30 00:26:13,409 - INFO -   Class 15: 18 samples
2025-07-30 00:26:13,410 - INFO -  ‚úì Balanced: 18 samples per class
2025-07-30 00:26:13,410 - INFO -  Using stratified split strategy
2025-07-30 00:26:13,410 - INFO -  VAL dataset: 30 original files
2025-07-30 00:26:13,410 - INFO -  No augmentation enabled: 30 total samples
2025-07-30 00:26:13,410 - INFO -  VAL class distribution:
2025-07-30 00:26:13,410 - INFO -   Class 1: 2 samples
2025-07-30 00:26:13,410 - INFO -   Class 2: 2 samples
2025-07-30 00:26:13,410 - INFO -   Class 3: 2 samples
2025-07-30 00:26:13,410 - INFO -   Class 4: 2 samples
2025-07-30 00:26:13,410 - INFO -   Class 5: 2 samples
2025-07-30 00:26:13,410 - INFO -   Class 6: 2 samples
2025-07-30 00:26:13,410 - INFO -   Class 7: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 8: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 9: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 10: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 11: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 12: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 13: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 14: 2 samples
2025-07-30 00:26:13,411 - INFO -   Class 15: 2 samples
2025-07-30 00:26:13,411 - INFO -  ‚úì Balanced: 2 samples per class
2025-07-30 00:26:13,411 - INFO - 
2025-07-30 00:26:13,411 - INFO - Dataset summary:
2025-07-30 00:26:13,411 - INFO -   Total classes: 15
2025-07-30 00:26:13,411 - INFO -   Train samples: 1080
2025-07-30 00:26:13,411 - INFO -   Val samples: 30
2025-07-30 00:26:13,411 - INFO -   Strategy: Stratified split
2025-07-30 00:26:13,411 - INFO - 
2025-07-30 00:26:13,411 - INFO - Creating data loaders...
2025-07-30 00:26:13,411 - INFO -  Train batches: 135
2025-07-30 00:26:13,412 - INFO -  Valid batches: 4
2025-07-30 00:26:13,412 - INFO -  Batch size: 8
2025-07-30 00:26:13,412 - INFO -  Data Augmentation (translation + scaling): 270 original ‚Üí 1080 total samples
2025-07-30 00:26:13,412 - INFO -  Augmentation combinations: ['original', 'translation', 'scaling', 'translation+scaling']
2025-07-30 00:26:13,447 - INFO -  Sample keypoints shape: torch.Size([8, 60, 75, 2])
2025-07-30 00:26:13,447 - INFO -  Sample labels shape: torch.Size([8])
2025-07-30 00:26:13,447 - INFO - 
2025-07-30 00:26:13,447 - INFO - Creating adjacency matrix...
2025-07-30 00:26:13,448 - INFO -  Adjacency matrix shape: torch.Size([75, 75])
2025-07-30 00:26:13,448 - INFO -  Number of vertices: 75
2025-07-30 00:26:13,448 - INFO - 
2025-07-30 00:26:13,448 - INFO - Creating model...
2025-07-30 00:26:13,802 - INFO - Model created with 277393 parameters
2025-07-30 00:26:13,802 - INFO - 
2025-07-30 00:26:13,802 - INFO - Starting training...
2025-07-30 00:26:13,802 - INFO -  Training configuration:
2025-07-30 00:26:13,802 - INFO -   - Epochs: 300
2025-07-30 00:26:13,802 - INFO -   - Batch size: 8
2025-07-30 00:26:13,802 - INFO -   - Learning rate: 0.001
2025-07-30 00:26:13,802 - INFO -   - Optimizer: adam
2025-07-30 00:26:13,802 - INFO -   - Scheduler: step
2025-07-30 00:26:13,802 - INFO -   - Early stopping patience: 50
2025-07-30 00:26:16,821 - INFO - Epoch 001/300 | Train Loss: 2.2294 Acc: 21.85% | Val Loss: 1.6799 Acc: 33.33% | LR: 0.00100000
2025-07-30 00:26:17,885 - INFO - Epoch 002/300 | Train Loss: 1.8231 Acc: 34.26% | Val Loss: 1.2726 Acc: 60.00% | LR: 0.00100000
2025-07-30 00:26:18,921 - INFO - Epoch 003/300 | Train Loss: 1.5759 Acc: 43.89% | Val Loss: 1.0487 Acc: 66.67% | LR: 0.00100000
2025-07-30 00:26:19,999 - INFO - Epoch 004/300 | Train Loss: 1.4611 Acc: 45.93% | Val Loss: 0.9260 Acc: 70.00% | LR: 0.00100000
2025-07-30 00:26:21,061 - INFO - Epoch 005/300 | Train Loss: 1.2978 Acc: 54.44% | Val Loss: 0.8780 Acc: 73.33% | LR: 0.00100000
2025-07-30 00:26:22,115 - INFO - Epoch 006/300 | Train Loss: 1.1643 Acc: 58.70% | Val Loss: 0.7093 Acc: 76.67% | LR: 0.00100000
2025-07-30 00:26:23,191 - INFO - Epoch 007/300 | Train Loss: 1.0563 Acc: 62.22% | Val Loss: 0.5549 Acc: 86.67% | LR: 0.00100000
2025-07-30 00:26:24,281 - INFO - Epoch 008/300 | Train Loss: 1.0034 Acc: 66.30% | Val Loss: 0.7006 Acc: 70.00% | LR: 0.00100000
2025-07-30 00:26:25,340 - INFO - Epoch 009/300 | Train Loss: 0.8306 Acc: 70.65% | Val Loss: 0.4976 Acc: 80.00% | LR: 0.00100000
2025-07-30 00:26:26,417 - INFO - Epoch 010/300 | Train Loss: 0.8211 Acc: 69.44% | Val Loss: 0.5289 Acc: 73.33% | LR: 0.00100000
2025-07-30 00:26:27,490 - INFO - Epoch 011/300 | Train Loss: 0.7598 Acc: 73.43% | Val Loss: 0.4637 Acc: 80.00% | LR: 0.00100000
2025-07-30 00:26:28,580 - INFO - Epoch 012/300 | Train Loss: 0.7529 Acc: 75.65% | Val Loss: 0.5198 Acc: 80.00% | LR: 0.00100000
2025-07-30 00:26:29,673 - INFO - Epoch 013/300 | Train Loss: 0.6169 Acc: 77.78% | Val Loss: 0.3231 Acc: 86.67% | LR: 0.00100000
2025-07-30 00:26:30,869 - INFO - Epoch 014/300 | Train Loss: 0.5742 Acc: 78.80% | Val Loss: 0.3380 Acc: 83.33% | LR: 0.00100000
2025-07-30 00:26:31,972 - INFO - Epoch 015/300 | Train Loss: 0.5911 Acc: 79.26% | Val Loss: 0.3209 Acc: 83.33% | LR: 0.00100000
2025-07-30 00:26:33,033 - INFO - Epoch 016/300 | Train Loss: 0.5087 Acc: 81.39% | Val Loss: 0.2212 Acc: 90.00% | LR: 0.00100000
2025-07-30 00:26:34,147 - INFO - Epoch 017/300 | Train Loss: 0.4636 Acc: 84.81% | Val Loss: 0.2800 Acc: 90.00% | LR: 0.00100000
2025-07-30 00:26:35,246 - INFO - Epoch 018/300 | Train Loss: 0.4726 Acc: 84.35% | Val Loss: 0.3333 Acc: 86.67% | LR: 0.00100000
2025-07-30 00:26:36,349 - INFO - Epoch 019/300 | Train Loss: 0.4536 Acc: 84.63% | Val Loss: 0.3409 Acc: 80.00% | LR: 0.00100000
2025-07-30 00:26:37,421 - INFO - Epoch 020/300 | Train Loss: 0.3743 Acc: 86.67% | Val Loss: 0.3237 Acc: 93.33% | LR: 0.00050000
2025-07-30 00:26:38,551 - INFO - Epoch 021/300 | Train Loss: 0.2805 Acc: 91.02% | Val Loss: 0.1526 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:39,639 - INFO - Epoch 022/300 | Train Loss: 0.2172 Acc: 92.69% | Val Loss: 0.2825 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:40,736 - INFO - Epoch 023/300 | Train Loss: 0.2288 Acc: 92.96% | Val Loss: 0.1741 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:41,804 - INFO - Epoch 024/300 | Train Loss: 0.1981 Acc: 94.07% | Val Loss: 0.2384 Acc: 86.67% | LR: 0.00050000
2025-07-30 00:26:42,884 - INFO - Epoch 025/300 | Train Loss: 0.2067 Acc: 93.98% | Val Loss: 0.2861 Acc: 86.67% | LR: 0.00050000
2025-07-30 00:26:43,965 - INFO - Epoch 026/300 | Train Loss: 0.2193 Acc: 94.07% | Val Loss: 0.2947 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:45,065 - INFO - Epoch 027/300 | Train Loss: 0.1997 Acc: 93.52% | Val Loss: 0.1778 Acc: 96.67% | LR: 0.00050000
2025-07-30 00:26:46,139 - INFO - Epoch 028/300 | Train Loss: 0.1508 Acc: 94.91% | Val Loss: 0.1544 Acc: 93.33% | LR: 0.00050000
2025-07-30 00:26:47,219 - INFO - Epoch 029/300 | Train Loss: 0.1629 Acc: 94.63% | Val Loss: 0.1828 Acc: 93.33% | LR: 0.00050000
2025-07-30 00:26:48,297 - INFO - Epoch 030/300 | Train Loss: 0.1616 Acc: 94.91% | Val Loss: 0.1855 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:49,412 - INFO - Epoch 031/300 | Train Loss: 0.1481 Acc: 95.83% | Val Loss: 0.2386 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:50,536 - INFO - Epoch 032/300 | Train Loss: 0.1400 Acc: 95.46% | Val Loss: 0.1480 Acc: 93.33% | LR: 0.00050000
2025-07-30 00:26:51,755 - INFO - Epoch 033/300 | Train Loss: 0.1207 Acc: 96.11% | Val Loss: 0.3611 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:52,808 - INFO - Epoch 034/300 | Train Loss: 0.1637 Acc: 95.09% | Val Loss: 0.2685 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:53,855 - INFO - Epoch 035/300 | Train Loss: 0.1255 Acc: 96.30% | Val Loss: 0.2208 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:54,895 - INFO - Epoch 036/300 | Train Loss: 0.1100 Acc: 97.31% | Val Loss: 0.2394 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:55,942 - INFO - Epoch 037/300 | Train Loss: 0.1136 Acc: 96.48% | Val Loss: 0.3038 Acc: 86.67% | LR: 0.00050000
2025-07-30 00:26:57,055 - INFO - Epoch 038/300 | Train Loss: 0.1397 Acc: 95.83% | Val Loss: 0.3078 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:58,260 - INFO - Epoch 039/300 | Train Loss: 0.1072 Acc: 96.76% | Val Loss: 0.2026 Acc: 90.00% | LR: 0.00050000
2025-07-30 00:26:59,559 - INFO - Epoch 040/300 | Train Loss: 0.1203 Acc: 96.39% | Val Loss: 0.2386 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:00,857 - INFO - Epoch 041/300 | Train Loss: 0.0894 Acc: 97.87% | Val Loss: 0.2641 Acc: 93.33% | LR: 0.00025000
2025-07-30 00:27:02,161 - INFO - Epoch 042/300 | Train Loss: 0.0588 Acc: 98.43% | Val Loss: 0.3020 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:03,376 - INFO - Epoch 043/300 | Train Loss: 0.0643 Acc: 98.15% | Val Loss: 0.2510 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:04,576 - INFO - Epoch 044/300 | Train Loss: 0.0627 Acc: 98.52% | Val Loss: 0.3201 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:05,808 - INFO - Epoch 045/300 | Train Loss: 0.0192 Acc: 99.63% | Val Loss: 0.3228 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:06,958 - INFO - Epoch 046/300 | Train Loss: 0.0733 Acc: 98.43% | Val Loss: 0.2925 Acc: 93.33% | LR: 0.00025000
2025-07-30 00:27:08,072 - INFO - Epoch 047/300 | Train Loss: 0.0294 Acc: 99.44% | Val Loss: 0.2832 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:09,141 - INFO - Epoch 048/300 | Train Loss: 0.0629 Acc: 98.70% | Val Loss: 0.3593 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:10,258 - INFO - Epoch 049/300 | Train Loss: 0.0382 Acc: 98.89% | Val Loss: 0.2945 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:11,348 - INFO - Epoch 050/300 | Train Loss: 0.0454 Acc: 98.70% | Val Loss: 0.2968 Acc: 93.33% | LR: 0.00025000
2025-07-30 00:27:12,439 - INFO - Epoch 051/300 | Train Loss: 0.0609 Acc: 98.52% | Val Loss: 0.2868 Acc: 93.33% | LR: 0.00025000
2025-07-30 00:27:13,515 - INFO - Epoch 052/300 | Train Loss: 0.0316 Acc: 99.17% | Val Loss: 0.3619 Acc: 93.33% | LR: 0.00025000
2025-07-30 00:27:14,576 - INFO - Epoch 053/300 | Train Loss: 0.0293 Acc: 99.26% | Val Loss: 0.3536 Acc: 93.33% | LR: 0.00025000
2025-07-30 00:27:15,662 - INFO - Epoch 054/300 | Train Loss: 0.0352 Acc: 99.07% | Val Loss: 0.3422 Acc: 93.33% | LR: 0.00025000
2025-07-30 00:27:16,800 - INFO - Epoch 055/300 | Train Loss: 0.0423 Acc: 99.07% | Val Loss: 0.3419 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:17,876 - INFO - Epoch 056/300 | Train Loss: 0.0427 Acc: 98.52% | Val Loss: 0.3913 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:18,964 - INFO - Epoch 057/300 | Train Loss: 0.0358 Acc: 99.07% | Val Loss: 0.4110 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:20,089 - INFO - Epoch 058/300 | Train Loss: 0.0471 Acc: 98.89% | Val Loss: 0.4668 Acc: 86.67% | LR: 0.00025000
2025-07-30 00:27:21,179 - INFO - Epoch 059/300 | Train Loss: 0.0629 Acc: 98.52% | Val Loss: 0.3899 Acc: 90.00% | LR: 0.00025000
2025-07-30 00:27:22,240 - INFO - Epoch 060/300 | Train Loss: 0.0380 Acc: 99.35% | Val Loss: 0.4026 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:23,294 - INFO - Epoch 061/300 | Train Loss: 0.0169 Acc: 99.63% | Val Loss: 0.3718 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:24,338 - INFO - Epoch 062/300 | Train Loss: 0.0565 Acc: 99.07% | Val Loss: 0.3760 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:25,376 - INFO - Epoch 063/300 | Train Loss: 0.0401 Acc: 98.80% | Val Loss: 0.3397 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:26,429 - INFO - Epoch 064/300 | Train Loss: 0.0155 Acc: 99.44% | Val Loss: 0.3627 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:27,488 - INFO - Epoch 065/300 | Train Loss: 0.0307 Acc: 99.26% | Val Loss: 0.3879 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:28,533 - INFO - Epoch 066/300 | Train Loss: 0.0268 Acc: 99.35% | Val Loss: 0.3547 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:29,574 - INFO - Epoch 067/300 | Train Loss: 0.0172 Acc: 99.72% | Val Loss: 0.3553 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:30,664 - INFO - Epoch 068/300 | Train Loss: 0.0244 Acc: 99.35% | Val Loss: 0.4271 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:31,773 - INFO - Epoch 069/300 | Train Loss: 0.0363 Acc: 99.07% | Val Loss: 0.3632 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:32,903 - INFO - Epoch 070/300 | Train Loss: 0.0460 Acc: 98.89% | Val Loss: 0.3385 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:34,062 - INFO - Epoch 071/300 | Train Loss: 0.0274 Acc: 99.44% | Val Loss: 0.3171 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:35,193 - INFO - Epoch 072/300 | Train Loss: 0.0284 Acc: 98.80% | Val Loss: 0.3672 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:36,303 - INFO - Epoch 073/300 | Train Loss: 0.0225 Acc: 99.63% | Val Loss: 0.3960 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:37,374 - INFO - Epoch 074/300 | Train Loss: 0.0207 Acc: 99.54% | Val Loss: 0.3969 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:38,437 - INFO - Epoch 075/300 | Train Loss: 0.0127 Acc: 99.63% | Val Loss: 0.3782 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:39,489 - INFO - Epoch 076/300 | Train Loss: 0.0267 Acc: 99.54% | Val Loss: 0.2595 Acc: 93.33% | LR: 0.00012500
2025-07-30 00:27:40,548 - INFO - Epoch 077/300 | Train Loss: 0.0154 Acc: 99.54% | Val Loss: 0.3376 Acc: 90.00% | LR: 0.00012500
2025-07-30 00:27:40,548 - INFO - Early stopping triggered after 77 epochs
2025-07-30 00:27:40,548 - INFO - Training completed. Best validation accuracy: 96.67% (Train: 93.52%)
2025-07-30 00:27:40,548 - INFO - 
2025-07-30 00:27:40,548 - INFO - Generating training visualizations...
2025-07-30 00:27:40,548 - INFO - Loading best model from: outputs/models/best_hgc_lstm.pth
2025-07-30 00:27:41,207 - INFO - Training curves saved to: training_plots/training_curves.png
2025-07-30 00:27:55,101 - INFO - 
2025-07-30 00:27:55,102 - INFO - üìä TRAINING SUMMARY:
2025-07-30 00:27:55,102 - INFO -    Best Validation Accuracy: 96.67% (Epoch 27)
2025-07-30 00:27:55,102 - INFO -    Final Training Accuracy: 99.54%
2025-07-30 00:27:55,102 - INFO -  Analyzing model performance on validation set...
2025-07-30 00:27:55,629 - INFO - Confusion matrix saved to: training_plots/confusion_matrix.png
2025-07-30 00:27:57,442 - INFO - 
2025-07-30 00:27:57,442 - INFO - ============================================================
2025-07-30 00:27:57,443 - INFO - CLASSIFICATION REPORT
2025-07-30 00:27:57,443 - INFO - ============================================================
2025-07-30 00:27:57,447 - INFO -               precision    recall  f1-score   support
2025-07-30 00:27:57,447 - INFO - 
2025-07-30 00:27:57,447 - INFO -      Class_1       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -      Class_2       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -      Class_3       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -      Class_4       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -      Class_5       1.00      0.50      0.67         2
2025-07-30 00:27:57,447 - INFO -      Class_6       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -      Class_7       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -      Class_8       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -      Class_9       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -     Class_10       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -     Class_11       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -     Class_12       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -     Class_13       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO -     Class_14       0.67      1.00      0.80         2
2025-07-30 00:27:57,447 - INFO -     Class_15       1.00      1.00      1.00         2
2025-07-30 00:27:57,447 - INFO - 
2025-07-30 00:27:57,447 - INFO -     accuracy                           0.97        30
2025-07-30 00:27:57,448 - INFO -    macro avg       0.98      0.97      0.96        30
2025-07-30 00:27:57,448 - INFO - weighted avg       0.98      0.97      0.96        30
2025-07-30 00:27:57,448 - INFO - 
2025-07-30 00:27:57,448 - INFO - ================================================================================
2025-07-30 00:27:57,448 - INFO - üéâ TRAINING COMPLETED SUCCESSFULLY!
2025-07-30 00:27:57,448 - INFO - ================================================================================
2025-07-30 00:27:57,448 - INFO - üèÜ Best validation accuracy: 96.67%
2025-07-30 00:27:57,448 - INFO - üíæ Model saved to: outputs/models/best_hgc_lstm.pth
2025-07-30 00:27:57,448 - INFO - üìä Plots saved to: outputs/plots
2025-07-30 00:27:57,448 - INFO - üìù Training log saved to: /home/na/VSLR/outputs/logs/training_20250730_002613.log
2025-07-30 00:27:57,448 - INFO - üìÖ End time: 2025-07-30 00:27:57
2025-07-30 00:27:57,448 - INFO - ================================================================================
