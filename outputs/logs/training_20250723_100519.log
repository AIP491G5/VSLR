2025-07-23 10:05:19,070 - INFO - ================================================================================
2025-07-23 10:05:19,070 - INFO - üöÄ VSLR Training Started
2025-07-23 10:05:19,070 - INFO - ================================================================================
2025-07-23 10:05:19,070 - INFO - üìù Log file: /home/na/VSLR/outputs/logs/training_20250723_100519.log
2025-07-23 10:05:19,070 - INFO - üìÖ Start time: 2025-07-23 10:05:19
2025-07-23 10:05:19,123 - INFO - Using device: cuda
2025-07-23 10:05:19,123 - INFO - Configuration loaded
2025-07-23 10:05:19,123 - INFO - Loading labels...
2025-07-23 10:05:19,126 - INFO -  15 classes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
2025-07-23 10:05:19,126 - INFO -  300 videos
2025-07-23 10:05:19,126 - INFO - 
2025-07-23 10:05:19,127 - INFO -  Creating datasets...
2025-07-23 10:05:19,127 - INFO - Configuration:
2025-07-23 10:05:19,127 - INFO -    Split strategy: Stratified
2025-07-23 10:05:19,127 - INFO -    Train augmentations: ['flip', 'translation', 'scaling']
2025-07-23 10:05:19,127 - INFO -    Val augmentations: None (for fair evaluation)
2025-07-23 10:05:19,127 - INFO -    Translation range: ¬±0.1
2025-07-23 10:05:19,127 - INFO -    Scale range: ¬±0.1
2025-07-23 10:05:19,127 - INFO -  Using stratified split strategy
2025-07-23 10:05:19,127 - INFO -  TRAIN dataset: 240 original files
2025-07-23 10:05:19,127 - INFO -  Augmentation enabled: 1920 total samples (x8)
2025-07-23 10:05:19,127 - INFO -   - Augmentations: ['flip', 'translation', 'scaling']
2025-07-23 10:05:19,127 - INFO -   - Total combinations: 8
2025-07-23 10:05:19,127 - INFO -   - Combinations: ['original', 'flip', 'translation', 'scaling', 'flip+translation', 'flip+scaling', 'translation+scaling', 'flip+translation+scaling']
2025-07-23 10:05:19,128 - INFO -  TRAIN class distribution:
2025-07-23 10:05:19,128 - INFO -   Class 1: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 2: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 3: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 4: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 5: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 6: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 7: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 8: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 9: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 10: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 11: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 12: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 13: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 14: 16 samples
2025-07-23 10:05:19,128 - INFO -   Class 15: 16 samples
2025-07-23 10:05:19,128 - INFO -  ‚úì Balanced: 16 samples per class
2025-07-23 10:05:19,129 - INFO -  Using stratified split strategy
2025-07-23 10:05:19,129 - INFO -  VAL dataset: 60 original files
2025-07-23 10:05:19,129 - INFO -  No augmentation enabled: 60 total samples
2025-07-23 10:05:19,129 - INFO -  VAL class distribution:
2025-07-23 10:05:19,129 - INFO -   Class 1: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 2: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 3: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 4: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 5: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 6: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 7: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 8: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 9: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 10: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 11: 4 samples
2025-07-23 10:05:19,129 - INFO -   Class 12: 4 samples
2025-07-23 10:05:19,130 - INFO -   Class 13: 4 samples
2025-07-23 10:05:19,130 - INFO -   Class 14: 4 samples
2025-07-23 10:05:19,130 - INFO -   Class 15: 4 samples
2025-07-23 10:05:19,130 - INFO -  ‚úì Balanced: 4 samples per class
2025-07-23 10:05:19,130 - INFO - 
2025-07-23 10:05:19,130 - INFO - Dataset summary:
2025-07-23 10:05:19,130 - INFO -   Total classes: 15
2025-07-23 10:05:19,130 - INFO -   Train samples: 1920
2025-07-23 10:05:19,130 - INFO -   Val samples: 60
2025-07-23 10:05:19,130 - INFO -   Strategy: Stratified split
2025-07-23 10:05:19,130 - INFO - 
2025-07-23 10:05:19,130 - INFO - Creating data loaders...
2025-07-23 10:05:19,130 - INFO -  Train batches: 240
2025-07-23 10:05:19,130 - INFO -  Valid batches: 8
2025-07-23 10:05:19,130 - INFO -  Batch size: 8
2025-07-23 10:05:19,130 - INFO -  Data Augmentation (flip + translation + scaling): 240 original ‚Üí 1920 total samples
2025-07-23 10:05:19,130 - INFO -  Augmentation combinations: ['original', 'flip', 'translation', 'scaling', 'flip+translation', 'flip+scaling', 'translation+scaling', 'flip+translation+scaling']
2025-07-23 10:05:19,134 - INFO -  Sample keypoints shape: torch.Size([8, 60, 75, 2])
2025-07-23 10:05:19,134 - INFO -  Sample labels shape: torch.Size([8])
2025-07-23 10:05:19,134 - INFO - 
2025-07-23 10:05:19,134 - INFO - Creating adjacency matrix...
2025-07-23 10:05:19,135 - INFO -  Adjacency matrix shape: torch.Size([75, 75])
2025-07-23 10:05:19,135 - INFO -  Number of vertices: 75
2025-07-23 10:05:19,135 - INFO - 
2025-07-23 10:05:19,135 - INFO - Creating model...
2025-07-23 10:05:19,372 - INFO - Model created with 285584 parameters
2025-07-23 10:05:19,372 - INFO - Model configuration:
2025-07-23 10:05:19,372 - INFO -   - GCN layers: 2
2025-07-23 10:05:19,372 - INFO -   - GCN hidden dim: 128
2025-07-23 10:05:19,372 - INFO -   - LSTM hidden dim: 128
2025-07-23 10:05:19,372 - INFO -   - LSTM layers: 1
2025-07-23 10:05:19,372 - INFO -   - Bidirectional: True
2025-07-23 10:05:19,372 - INFO -   - Dropout: 0.5
2025-07-23 10:05:19,372 - INFO -   - Pooling type: attention
2025-07-23 10:05:19,373 - INFO -   - Sequence length: 60
2025-07-23 10:05:19,373 - INFO -   - Number of vertices: 75
2025-07-23 10:05:19,373 - INFO -   - Using Attention Pooling with dropout: 0.5
2025-07-23 10:05:19,373 - INFO -   - Attention weights can be visualized after forward pass
2025-07-23 10:05:19,373 - INFO - 
2025-07-23 10:05:19,373 - INFO - Starting training...
2025-07-23 10:05:19,373 - INFO -  Training configuration:
2025-07-23 10:05:19,373 - INFO -   - Epochs: 300
2025-07-23 10:05:19,373 - INFO -   - Batch size: 8
2025-07-23 10:05:19,373 - INFO -   - Learning rate: 0.001
2025-07-23 10:05:19,373 - INFO -   - Optimizer: adam
2025-07-23 10:05:19,373 - INFO -   - Scheduler: step
2025-07-23 10:05:19,373 - INFO -   - Early stopping patience: 50
2025-07-23 10:05:22,022 - INFO - Epoch 001/300 | Train Loss: 2.7209 Acc: 06.46% | Val Loss: 2.7140 Acc: 06.67% | LR: 0.00100000
2025-07-23 10:05:23,653 - INFO - Epoch 002/300 | Train Loss: 2.7117 Acc: 06.82% | Val Loss: 2.7245 Acc: 05.00% | LR: 0.00100000
2025-07-23 10:05:25,287 - INFO - Epoch 003/300 | Train Loss: 2.6989 Acc: 07.60% | Val Loss: 2.7473 Acc: 06.67% | LR: 0.00100000
2025-07-23 10:05:26,921 - INFO - Epoch 004/300 | Train Loss: 2.6096 Acc: 13.28% | Val Loss: 2.4337 Acc: 10.00% | LR: 0.00100000
2025-07-23 10:05:28,549 - INFO - Epoch 005/300 | Train Loss: 2.3804 Acc: 16.77% | Val Loss: 2.2585 Acc: 16.67% | LR: 0.00100000
2025-07-23 10:05:30,177 - INFO - Epoch 006/300 | Train Loss: 2.2543 Acc: 20.26% | Val Loss: 2.2018 Acc: 18.33% | LR: 0.00100000
2025-07-23 10:05:31,824 - INFO - Epoch 007/300 | Train Loss: 2.1323 Acc: 25.21% | Val Loss: 2.0849 Acc: 26.67% | LR: 0.00100000
2025-07-23 10:05:33,457 - INFO - Epoch 008/300 | Train Loss: 2.0335 Acc: 27.66% | Val Loss: 1.9476 Acc: 30.00% | LR: 0.00100000
2025-07-23 10:05:35,091 - INFO - Epoch 009/300 | Train Loss: 1.9347 Acc: 31.72% | Val Loss: 1.7902 Acc: 33.33% | LR: 0.00100000
2025-07-23 10:05:36,718 - INFO - Epoch 010/300 | Train Loss: 1.8364 Acc: 34.22% | Val Loss: 1.7107 Acc: 36.67% | LR: 0.00100000
2025-07-23 10:05:38,336 - INFO - Epoch 011/300 | Train Loss: 1.7572 Acc: 38.02% | Val Loss: 1.6485 Acc: 38.33% | LR: 0.00100000
2025-07-23 10:05:39,947 - INFO - Epoch 012/300 | Train Loss: 1.6673 Acc: 40.99% | Val Loss: 1.6751 Acc: 36.67% | LR: 0.00100000
2025-07-23 10:05:41,577 - INFO - Epoch 013/300 | Train Loss: 1.5493 Acc: 45.89% | Val Loss: 1.3186 Acc: 46.67% | LR: 0.00100000
2025-07-23 10:05:43,229 - INFO - Epoch 014/300 | Train Loss: 1.5021 Acc: 47.45% | Val Loss: 1.1250 Acc: 55.00% | LR: 0.00100000
2025-07-23 10:05:44,855 - INFO - Epoch 015/300 | Train Loss: 1.4399 Acc: 48.23% | Val Loss: 1.2497 Acc: 51.67% | LR: 0.00100000
2025-07-23 10:05:46,498 - INFO - Epoch 016/300 | Train Loss: 1.3613 Acc: 50.21% | Val Loss: 1.0987 Acc: 58.33% | LR: 0.00100000
2025-07-23 10:05:48,175 - INFO - Epoch 017/300 | Train Loss: 1.2595 Acc: 57.55% | Val Loss: 1.0092 Acc: 65.00% | LR: 0.00100000
2025-07-23 10:05:49,947 - INFO - Epoch 018/300 | Train Loss: 1.2729 Acc: 55.68% | Val Loss: 1.0429 Acc: 58.33% | LR: 0.00100000
2025-07-23 10:05:51,713 - INFO - Epoch 019/300 | Train Loss: 1.1705 Acc: 59.01% | Val Loss: 0.8698 Acc: 70.00% | LR: 0.00100000
2025-07-23 10:05:53,483 - INFO - Epoch 020/300 | Train Loss: 1.1121 Acc: 61.30% | Val Loss: 0.8483 Acc: 66.67% | LR: 0.00050000
2025-07-23 10:05:55,189 - INFO - Epoch 021/300 | Train Loss: 0.9797 Acc: 66.82% | Val Loss: 0.6488 Acc: 78.33% | LR: 0.00050000
2025-07-23 10:05:56,865 - INFO - Epoch 022/300 | Train Loss: 0.8866 Acc: 68.75% | Val Loss: 0.5612 Acc: 83.33% | LR: 0.00050000
2025-07-23 10:05:58,515 - INFO - Epoch 023/300 | Train Loss: 0.8406 Acc: 71.77% | Val Loss: 0.7013 Acc: 76.67% | LR: 0.00050000
2025-07-23 10:06:00,167 - INFO - Epoch 024/300 | Train Loss: 0.7897 Acc: 73.80% | Val Loss: 0.6144 Acc: 81.67% | LR: 0.00050000
2025-07-23 10:06:01,808 - INFO - Epoch 025/300 | Train Loss: 0.7458 Acc: 74.90% | Val Loss: 0.4859 Acc: 86.67% | LR: 0.00050000
2025-07-23 10:06:03,427 - INFO - Epoch 026/300 | Train Loss: 0.7778 Acc: 73.07% | Val Loss: 0.5362 Acc: 78.33% | LR: 0.00050000
2025-07-23 10:06:05,042 - INFO - Epoch 027/300 | Train Loss: 0.6957 Acc: 76.35% | Val Loss: 0.5035 Acc: 88.33% | LR: 0.00050000
2025-07-23 10:06:06,667 - INFO - Epoch 028/300 | Train Loss: 0.7096 Acc: 75.94% | Val Loss: 0.6880 Acc: 76.67% | LR: 0.00050000
2025-07-23 10:06:08,287 - INFO - Epoch 029/300 | Train Loss: 0.6570 Acc: 78.02% | Val Loss: 0.5954 Acc: 73.33% | LR: 0.00050000
2025-07-23 10:06:09,948 - INFO - Epoch 030/300 | Train Loss: 0.6469 Acc: 77.34% | Val Loss: 0.5268 Acc: 83.33% | LR: 0.00050000
2025-07-23 10:06:11,612 - INFO - Epoch 031/300 | Train Loss: 0.6442 Acc: 77.66% | Val Loss: 0.5876 Acc: 80.00% | LR: 0.00050000
2025-07-23 10:06:13,257 - INFO - Epoch 032/300 | Train Loss: 0.5894 Acc: 81.25% | Val Loss: 0.5011 Acc: 85.00% | LR: 0.00050000
2025-07-23 10:06:14,906 - INFO - Epoch 033/300 | Train Loss: 0.5826 Acc: 80.47% | Val Loss: 0.5845 Acc: 81.67% | LR: 0.00050000
2025-07-23 10:06:16,547 - INFO - Epoch 034/300 | Train Loss: 0.5279 Acc: 83.28% | Val Loss: 0.4533 Acc: 86.67% | LR: 0.00050000
2025-07-23 10:06:18,181 - INFO - Epoch 035/300 | Train Loss: 0.5661 Acc: 82.45% | Val Loss: 0.5504 Acc: 73.33% | LR: 0.00050000
2025-07-23 10:06:19,845 - INFO - Epoch 036/300 | Train Loss: 0.5236 Acc: 83.96% | Val Loss: 0.4278 Acc: 88.33% | LR: 0.00050000
2025-07-23 10:06:21,487 - INFO - Epoch 037/300 | Train Loss: 0.4731 Acc: 85.00% | Val Loss: 0.6442 Acc: 85.00% | LR: 0.00050000
2025-07-23 10:06:23,134 - INFO - Epoch 038/300 | Train Loss: 0.4646 Acc: 84.22% | Val Loss: 0.6196 Acc: 85.00% | LR: 0.00050000
2025-07-23 10:06:24,784 - INFO - Epoch 039/300 | Train Loss: 0.4760 Acc: 85.57% | Val Loss: 0.4143 Acc: 91.67% | LR: 0.00050000
2025-07-23 10:06:26,439 - INFO - Epoch 040/300 | Train Loss: 0.4272 Acc: 86.15% | Val Loss: 0.4302 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:28,070 - INFO - Epoch 041/300 | Train Loss: 0.3627 Acc: 88.70% | Val Loss: 0.4498 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:29,696 - INFO - Epoch 042/300 | Train Loss: 0.3221 Acc: 90.83% | Val Loss: 0.3584 Acc: 93.33% | LR: 0.00025000
2025-07-23 10:06:31,406 - INFO - Epoch 043/300 | Train Loss: 0.2895 Acc: 91.15% | Val Loss: 0.3986 Acc: 91.67% | LR: 0.00025000
2025-07-23 10:06:33,168 - INFO - Epoch 044/300 | Train Loss: 0.3253 Acc: 91.51% | Val Loss: 0.4059 Acc: 93.33% | LR: 0.00025000
2025-07-23 10:06:34,945 - INFO - Epoch 045/300 | Train Loss: 0.3167 Acc: 90.78% | Val Loss: 0.5240 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:36,661 - INFO - Epoch 046/300 | Train Loss: 0.2196 Acc: 93.54% | Val Loss: 0.4864 Acc: 91.67% | LR: 0.00025000
2025-07-23 10:06:38,294 - INFO - Epoch 047/300 | Train Loss: 0.2859 Acc: 92.97% | Val Loss: 0.3826 Acc: 91.67% | LR: 0.00025000
2025-07-23 10:06:39,905 - INFO - Epoch 048/300 | Train Loss: 0.2394 Acc: 93.39% | Val Loss: 0.3334 Acc: 91.67% | LR: 0.00025000
2025-07-23 10:06:41,525 - INFO - Epoch 049/300 | Train Loss: 0.2575 Acc: 92.29% | Val Loss: 0.5306 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:43,138 - INFO - Epoch 050/300 | Train Loss: 0.2901 Acc: 92.19% | Val Loss: 0.4115 Acc: 91.67% | LR: 0.00025000
2025-07-23 10:06:44,763 - INFO - Epoch 051/300 | Train Loss: 0.2223 Acc: 93.70% | Val Loss: 0.4762 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:46,411 - INFO - Epoch 052/300 | Train Loss: 0.2179 Acc: 93.75% | Val Loss: 0.4120 Acc: 88.33% | LR: 0.00025000
2025-07-23 10:06:48,040 - INFO - Epoch 053/300 | Train Loss: 0.2321 Acc: 93.49% | Val Loss: 0.5485 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:49,718 - INFO - Epoch 054/300 | Train Loss: 0.2607 Acc: 92.97% | Val Loss: 0.4833 Acc: 91.67% | LR: 0.00025000
2025-07-23 10:06:51,489 - INFO - Epoch 055/300 | Train Loss: 0.2343 Acc: 93.39% | Val Loss: 0.5482 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:53,255 - INFO - Epoch 056/300 | Train Loss: 0.2597 Acc: 92.81% | Val Loss: 0.5700 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:55,030 - INFO - Epoch 057/300 | Train Loss: 0.2284 Acc: 93.85% | Val Loss: 0.5589 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:56,736 - INFO - Epoch 058/300 | Train Loss: 0.2360 Acc: 93.85% | Val Loss: 0.3643 Acc: 91.67% | LR: 0.00025000
2025-07-23 10:06:58,365 - INFO - Epoch 059/300 | Train Loss: 0.2167 Acc: 94.48% | Val Loss: 0.5909 Acc: 90.00% | LR: 0.00025000
2025-07-23 10:06:59,993 - INFO - Epoch 060/300 | Train Loss: 0.2554 Acc: 93.39% | Val Loss: 0.5555 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:01,632 - INFO - Epoch 061/300 | Train Loss: 0.1498 Acc: 95.52% | Val Loss: 0.5399 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:03,262 - INFO - Epoch 062/300 | Train Loss: 0.1351 Acc: 96.35% | Val Loss: 0.5370 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:04,889 - INFO - Epoch 063/300 | Train Loss: 0.1316 Acc: 96.20% | Val Loss: 0.5553 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:06,515 - INFO - Epoch 064/300 | Train Loss: 0.1389 Acc: 96.30% | Val Loss: 0.5356 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:08,134 - INFO - Epoch 065/300 | Train Loss: 0.1301 Acc: 96.51% | Val Loss: 0.5409 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:09,754 - INFO - Epoch 066/300 | Train Loss: 0.1214 Acc: 96.51% | Val Loss: 0.4823 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:11,391 - INFO - Epoch 067/300 | Train Loss: 0.1396 Acc: 96.77% | Val Loss: 0.5506 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:13,007 - INFO - Epoch 068/300 | Train Loss: 0.1318 Acc: 96.67% | Val Loss: 0.5279 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:14,619 - INFO - Epoch 069/300 | Train Loss: 0.1299 Acc: 96.93% | Val Loss: 0.4003 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:16,235 - INFO - Epoch 070/300 | Train Loss: 0.1286 Acc: 96.61% | Val Loss: 0.5655 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:17,846 - INFO - Epoch 071/300 | Train Loss: 0.1236 Acc: 96.51% | Val Loss: 0.5214 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:19,457 - INFO - Epoch 072/300 | Train Loss: 0.1066 Acc: 97.14% | Val Loss: 0.4405 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:21,082 - INFO - Epoch 073/300 | Train Loss: 0.1395 Acc: 95.94% | Val Loss: 0.5647 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:22,716 - INFO - Epoch 074/300 | Train Loss: 0.1231 Acc: 96.93% | Val Loss: 0.5743 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:24,340 - INFO - Epoch 075/300 | Train Loss: 0.1208 Acc: 96.98% | Val Loss: 0.5861 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:25,962 - INFO - Epoch 076/300 | Train Loss: 0.1031 Acc: 97.81% | Val Loss: 0.4891 Acc: 93.33% | LR: 0.00012500
2025-07-23 10:07:27,587 - INFO - Epoch 077/300 | Train Loss: 0.1244 Acc: 97.08% | Val Loss: 0.6115 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:29,201 - INFO - Epoch 078/300 | Train Loss: 0.1631 Acc: 96.61% | Val Loss: 0.5467 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:30,807 - INFO - Epoch 079/300 | Train Loss: 0.1164 Acc: 97.34% | Val Loss: 0.5228 Acc: 91.67% | LR: 0.00012500
2025-07-23 10:07:32,442 - INFO - Epoch 080/300 | Train Loss: 0.1162 Acc: 96.93% | Val Loss: 0.4589 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:07:34,054 - INFO - Epoch 081/300 | Train Loss: 0.1174 Acc: 97.50% | Val Loss: 0.4394 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:07:35,667 - INFO - Epoch 082/300 | Train Loss: 0.0933 Acc: 97.86% | Val Loss: 0.5077 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:07:37,283 - INFO - Epoch 083/300 | Train Loss: 0.0807 Acc: 97.97% | Val Loss: 0.5024 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:07:38,914 - INFO - Epoch 084/300 | Train Loss: 0.1083 Acc: 97.55% | Val Loss: 0.5732 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:07:40,534 - INFO - Epoch 085/300 | Train Loss: 0.0826 Acc: 97.92% | Val Loss: 0.5975 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:07:42,364 - INFO - Epoch 086/300 | Train Loss: 0.1059 Acc: 97.55% | Val Loss: 0.5348 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:07:44,186 - INFO - Epoch 087/300 | Train Loss: 0.0732 Acc: 98.07% | Val Loss: 0.4600 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:07:46,000 - INFO - Epoch 088/300 | Train Loss: 0.0891 Acc: 97.71% | Val Loss: 0.4942 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:07:47,831 - INFO - Epoch 089/300 | Train Loss: 0.0783 Acc: 97.81% | Val Loss: 0.4901 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:07:49,623 - INFO - Epoch 090/300 | Train Loss: 0.0824 Acc: 98.07% | Val Loss: 0.6113 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:07:51,447 - INFO - Epoch 091/300 | Train Loss: 0.1069 Acc: 97.60% | Val Loss: 0.5904 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:07:53,269 - INFO - Epoch 092/300 | Train Loss: 0.0943 Acc: 98.07% | Val Loss: 0.5728 Acc: 90.00% | LR: 0.00006250
2025-07-23 10:07:55,096 - INFO - Epoch 093/300 | Train Loss: 0.0807 Acc: 98.18% | Val Loss: 0.5953 Acc: 90.00% | LR: 0.00006250
2025-07-23 10:07:56,965 - INFO - Epoch 094/300 | Train Loss: 0.0718 Acc: 98.59% | Val Loss: 0.5269 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:07:58,827 - INFO - Epoch 095/300 | Train Loss: 0.0684 Acc: 98.28% | Val Loss: 0.6016 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:08:00,575 - INFO - Epoch 096/300 | Train Loss: 0.0962 Acc: 97.86% | Val Loss: 0.5252 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:08:02,319 - INFO - Epoch 097/300 | Train Loss: 0.0880 Acc: 97.92% | Val Loss: 0.5809 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:08:04,050 - INFO - Epoch 098/300 | Train Loss: 0.1038 Acc: 97.86% | Val Loss: 0.4355 Acc: 93.33% | LR: 0.00006250
2025-07-23 10:08:05,754 - INFO - Epoch 099/300 | Train Loss: 0.1397 Acc: 96.98% | Val Loss: 0.5423 Acc: 91.67% | LR: 0.00006250
2025-07-23 10:08:07,464 - INFO - Epoch 100/300 | Train Loss: 0.0916 Acc: 98.23% | Val Loss: 0.5649 Acc: 91.67% | LR: 0.00003125
2025-07-23 10:08:09,093 - INFO - Epoch 101/300 | Train Loss: 0.0762 Acc: 98.28% | Val Loss: 0.5866 Acc: 91.67% | LR: 0.00003125
2025-07-23 10:08:10,717 - INFO - Epoch 102/300 | Train Loss: 0.0582 Acc: 98.65% | Val Loss: 0.5361 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:12,339 - INFO - Epoch 103/300 | Train Loss: 0.0719 Acc: 98.23% | Val Loss: 0.5314 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:13,959 - INFO - Epoch 104/300 | Train Loss: 0.1039 Acc: 97.66% | Val Loss: 0.5327 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:15,579 - INFO - Epoch 105/300 | Train Loss: 0.0754 Acc: 98.07% | Val Loss: 0.4421 Acc: 91.67% | LR: 0.00003125
2025-07-23 10:08:17,199 - INFO - Epoch 106/300 | Train Loss: 0.0508 Acc: 98.75% | Val Loss: 0.5892 Acc: 91.67% | LR: 0.00003125
2025-07-23 10:08:18,813 - INFO - Epoch 107/300 | Train Loss: 0.0690 Acc: 98.54% | Val Loss: 0.5071 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:20,426 - INFO - Epoch 108/300 | Train Loss: 0.0802 Acc: 98.44% | Val Loss: 0.4665 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:22,041 - INFO - Epoch 109/300 | Train Loss: 0.0543 Acc: 98.59% | Val Loss: 0.5390 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:23,660 - INFO - Epoch 110/300 | Train Loss: 0.0666 Acc: 98.65% | Val Loss: 0.5651 Acc: 91.67% | LR: 0.00003125
2025-07-23 10:08:25,276 - INFO - Epoch 111/300 | Train Loss: 0.0545 Acc: 98.65% | Val Loss: 0.5151 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:26,944 - INFO - Epoch 112/300 | Train Loss: 0.0692 Acc: 98.33% | Val Loss: 0.5402 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:28,598 - INFO - Epoch 113/300 | Train Loss: 0.0385 Acc: 98.85% | Val Loss: 0.5571 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:30,235 - INFO - Epoch 114/300 | Train Loss: 0.0642 Acc: 98.49% | Val Loss: 0.5670 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:31,874 - INFO - Epoch 115/300 | Train Loss: 0.0759 Acc: 98.12% | Val Loss: 0.5293 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:33,494 - INFO - Epoch 116/300 | Train Loss: 0.0783 Acc: 98.12% | Val Loss: 0.5375 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:35,325 - INFO - Epoch 117/300 | Train Loss: 0.0427 Acc: 98.96% | Val Loss: 0.5195 Acc: 93.33% | LR: 0.00003125
2025-07-23 10:08:36,962 - INFO - Epoch 118/300 | Train Loss: 0.0616 Acc: 98.65% | Val Loss: 0.6074 Acc: 91.67% | LR: 0.00003125
2025-07-23 10:08:38,587 - INFO - Epoch 119/300 | Train Loss: 0.0503 Acc: 98.70% | Val Loss: 0.5519 Acc: 91.67% | LR: 0.00003125
2025-07-23 10:08:40,240 - INFO - Epoch 120/300 | Train Loss: 0.0619 Acc: 98.28% | Val Loss: 0.5522 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:41,893 - INFO - Epoch 121/300 | Train Loss: 0.0609 Acc: 98.23% | Val Loss: 0.5308 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:43,511 - INFO - Epoch 122/300 | Train Loss: 0.0598 Acc: 98.65% | Val Loss: 0.5349 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:45,150 - INFO - Epoch 123/300 | Train Loss: 0.0772 Acc: 98.23% | Val Loss: 0.5477 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:46,780 - INFO - Epoch 124/300 | Train Loss: 0.0268 Acc: 99.27% | Val Loss: 0.4408 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:48,401 - INFO - Epoch 125/300 | Train Loss: 0.0673 Acc: 98.54% | Val Loss: 0.5050 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:50,030 - INFO - Epoch 126/300 | Train Loss: 0.0512 Acc: 98.85% | Val Loss: 0.4941 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:51,643 - INFO - Epoch 127/300 | Train Loss: 0.0694 Acc: 98.70% | Val Loss: 0.4876 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:53,255 - INFO - Epoch 128/300 | Train Loss: 0.0744 Acc: 98.18% | Val Loss: 0.5498 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:54,860 - INFO - Epoch 129/300 | Train Loss: 0.0336 Acc: 99.06% | Val Loss: 0.4665 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:56,489 - INFO - Epoch 130/300 | Train Loss: 0.0572 Acc: 98.70% | Val Loss: 0.4842 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:08:58,098 - INFO - Epoch 131/300 | Train Loss: 0.0517 Acc: 98.49% | Val Loss: 0.5717 Acc: 91.67% | LR: 0.00001563
2025-07-23 10:08:59,699 - INFO - Epoch 132/300 | Train Loss: 0.0447 Acc: 98.65% | Val Loss: 0.5456 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:09:01,300 - INFO - Epoch 133/300 | Train Loss: 0.0915 Acc: 98.23% | Val Loss: 0.5519 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:09:02,916 - INFO - Epoch 134/300 | Train Loss: 0.0736 Acc: 98.54% | Val Loss: 0.5930 Acc: 91.67% | LR: 0.00001563
2025-07-23 10:09:04,538 - INFO - Epoch 135/300 | Train Loss: 0.0494 Acc: 99.01% | Val Loss: 0.5399 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:09:06,152 - INFO - Epoch 136/300 | Train Loss: 0.0558 Acc: 98.80% | Val Loss: 0.5697 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:09:07,760 - INFO - Epoch 137/300 | Train Loss: 0.0699 Acc: 98.49% | Val Loss: 0.5217 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:09:09,387 - INFO - Epoch 138/300 | Train Loss: 0.0543 Acc: 98.49% | Val Loss: 0.5620 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:09:11,021 - INFO - Epoch 139/300 | Train Loss: 0.0420 Acc: 99.17% | Val Loss: 0.5306 Acc: 93.33% | LR: 0.00001563
2025-07-23 10:09:12,664 - INFO - Epoch 140/300 | Train Loss: 0.0623 Acc: 98.49% | Val Loss: 0.4638 Acc: 95.00% | LR: 0.00000781
2025-07-23 10:09:14,286 - INFO - Epoch 141/300 | Train Loss: 0.0473 Acc: 98.96% | Val Loss: 0.5541 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:15,906 - INFO - Epoch 142/300 | Train Loss: 0.0449 Acc: 98.91% | Val Loss: 0.4543 Acc: 95.00% | LR: 0.00000781
2025-07-23 10:09:17,527 - INFO - Epoch 143/300 | Train Loss: 0.0327 Acc: 99.01% | Val Loss: 0.5234 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:19,197 - INFO - Epoch 144/300 | Train Loss: 0.0401 Acc: 99.01% | Val Loss: 0.5402 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:20,844 - INFO - Epoch 145/300 | Train Loss: 0.0666 Acc: 98.65% | Val Loss: 0.5230 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:22,485 - INFO - Epoch 146/300 | Train Loss: 0.0514 Acc: 98.80% | Val Loss: 0.6019 Acc: 91.67% | LR: 0.00000781
2025-07-23 10:09:24,101 - INFO - Epoch 147/300 | Train Loss: 0.0719 Acc: 98.33% | Val Loss: 0.5670 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:25,719 - INFO - Epoch 148/300 | Train Loss: 0.0480 Acc: 98.91% | Val Loss: 0.5161 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:27,346 - INFO - Epoch 149/300 | Train Loss: 0.0333 Acc: 99.17% | Val Loss: 0.5589 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:28,969 - INFO - Epoch 150/300 | Train Loss: 0.0741 Acc: 98.65% | Val Loss: 0.5364 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:30,699 - INFO - Epoch 151/300 | Train Loss: 0.0566 Acc: 98.80% | Val Loss: 0.4824 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:32,369 - INFO - Epoch 152/300 | Train Loss: 0.0432 Acc: 99.11% | Val Loss: 0.5559 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:34,015 - INFO - Epoch 153/300 | Train Loss: 0.0506 Acc: 98.70% | Val Loss: 0.5425 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:35,644 - INFO - Epoch 154/300 | Train Loss: 0.0389 Acc: 98.85% | Val Loss: 0.5120 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:37,308 - INFO - Epoch 155/300 | Train Loss: 0.0708 Acc: 98.49% | Val Loss: 0.5660 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:38,919 - INFO - Epoch 156/300 | Train Loss: 0.0478 Acc: 99.01% | Val Loss: 0.5249 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:40,535 - INFO - Epoch 157/300 | Train Loss: 0.0615 Acc: 98.65% | Val Loss: 0.4562 Acc: 95.00% | LR: 0.00000781
2025-07-23 10:09:42,151 - INFO - Epoch 158/300 | Train Loss: 0.0414 Acc: 99.01% | Val Loss: 0.5444 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:43,769 - INFO - Epoch 159/300 | Train Loss: 0.0537 Acc: 98.54% | Val Loss: 0.5165 Acc: 93.33% | LR: 0.00000781
2025-07-23 10:09:45,385 - INFO - Epoch 160/300 | Train Loss: 0.0439 Acc: 98.91% | Val Loss: 0.5124 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:09:47,034 - INFO - Epoch 161/300 | Train Loss: 0.0410 Acc: 98.80% | Val Loss: 0.4889 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:09:48,662 - INFO - Epoch 162/300 | Train Loss: 0.0453 Acc: 98.91% | Val Loss: 0.4620 Acc: 95.00% | LR: 0.00000391
2025-07-23 10:09:50,307 - INFO - Epoch 163/300 | Train Loss: 0.0359 Acc: 98.96% | Val Loss: 0.5709 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:09:51,936 - INFO - Epoch 164/300 | Train Loss: 0.0675 Acc: 98.33% | Val Loss: 0.5569 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:09:53,560 - INFO - Epoch 165/300 | Train Loss: 0.0548 Acc: 99.17% | Val Loss: 0.5178 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:09:55,181 - INFO - Epoch 166/300 | Train Loss: 0.0462 Acc: 99.06% | Val Loss: 0.4784 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:09:56,806 - INFO - Epoch 167/300 | Train Loss: 0.0494 Acc: 98.80% | Val Loss: 0.5634 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:09:58,435 - INFO - Epoch 168/300 | Train Loss: 0.0615 Acc: 98.49% | Val Loss: 0.5210 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:00,055 - INFO - Epoch 169/300 | Train Loss: 0.0387 Acc: 98.91% | Val Loss: 0.4644 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:01,667 - INFO - Epoch 170/300 | Train Loss: 0.0378 Acc: 98.80% | Val Loss: 0.5478 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:03,279 - INFO - Epoch 171/300 | Train Loss: 0.0596 Acc: 98.96% | Val Loss: 0.4840 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:04,894 - INFO - Epoch 172/300 | Train Loss: 0.0619 Acc: 98.54% | Val Loss: 0.4686 Acc: 95.00% | LR: 0.00000391
2025-07-23 10:10:06,500 - INFO - Epoch 173/300 | Train Loss: 0.0323 Acc: 99.01% | Val Loss: 0.5523 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:08,124 - INFO - Epoch 174/300 | Train Loss: 0.0675 Acc: 98.59% | Val Loss: 0.5678 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:09,733 - INFO - Epoch 175/300 | Train Loss: 0.0406 Acc: 98.85% | Val Loss: 0.5137 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:11,339 - INFO - Epoch 176/300 | Train Loss: 0.0491 Acc: 98.96% | Val Loss: 0.5499 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:13,027 - INFO - Epoch 177/300 | Train Loss: 0.0514 Acc: 99.01% | Val Loss: 0.5615 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:14,658 - INFO - Epoch 178/300 | Train Loss: 0.0461 Acc: 98.65% | Val Loss: 0.5288 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:16,291 - INFO - Epoch 179/300 | Train Loss: 0.0431 Acc: 98.96% | Val Loss: 0.5534 Acc: 93.33% | LR: 0.00000391
2025-07-23 10:10:18,085 - INFO - Epoch 180/300 | Train Loss: 0.0456 Acc: 98.70% | Val Loss: 0.4657 Acc: 95.00% | LR: 0.00000195
2025-07-23 10:10:19,858 - INFO - Epoch 181/300 | Train Loss: 0.0650 Acc: 98.59% | Val Loss: 0.4427 Acc: 95.00% | LR: 0.00000195
2025-07-23 10:10:21,564 - INFO - Epoch 182/300 | Train Loss: 0.0399 Acc: 99.01% | Val Loss: 0.5338 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:23,271 - INFO - Epoch 183/300 | Train Loss: 0.0657 Acc: 98.65% | Val Loss: 0.5583 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:25,073 - INFO - Epoch 184/300 | Train Loss: 0.0508 Acc: 98.80% | Val Loss: 0.4526 Acc: 95.00% | LR: 0.00000195
2025-07-23 10:10:26,821 - INFO - Epoch 185/300 | Train Loss: 0.0410 Acc: 98.85% | Val Loss: 0.5543 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:28,484 - INFO - Epoch 186/300 | Train Loss: 0.0476 Acc: 98.54% | Val Loss: 0.5313 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:30,203 - INFO - Epoch 187/300 | Train Loss: 0.0541 Acc: 98.65% | Val Loss: 0.5443 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:31,865 - INFO - Epoch 188/300 | Train Loss: 0.0439 Acc: 99.01% | Val Loss: 0.4934 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:33,501 - INFO - Epoch 189/300 | Train Loss: 0.0397 Acc: 99.06% | Val Loss: 0.4989 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:35,155 - INFO - Epoch 190/300 | Train Loss: 0.0584 Acc: 98.85% | Val Loss: 0.5211 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:36,818 - INFO - Epoch 191/300 | Train Loss: 0.0439 Acc: 98.70% | Val Loss: 0.5600 Acc: 91.67% | LR: 0.00000195
2025-07-23 10:10:38,440 - INFO - Epoch 192/300 | Train Loss: 0.0568 Acc: 98.59% | Val Loss: 0.5195 Acc: 93.33% | LR: 0.00000195
2025-07-23 10:10:38,440 - INFO - Early stopping triggered after 192 epochs
2025-07-23 10:10:38,440 - INFO - Training completed. Best validation accuracy: 95.00% (Train: 98.91%)
2025-07-23 10:10:38,440 - INFO - 
2025-07-23 10:10:38,440 - INFO - Generating training visualizations...
2025-07-23 10:10:38,440 - INFO - Loading best model from: outputs/models/best_hgc_lstm.pth
2025-07-23 10:10:38,963 - INFO - Training curves saved to: training_plots/training_curves.png
2025-07-23 10:10:42,680 - INFO - 
2025-07-23 10:10:42,680 - INFO - üìä TRAINING SUMMARY:
2025-07-23 10:10:42,680 - INFO -    Best Validation Accuracy: 95.00% (Epoch 140)
2025-07-23 10:10:42,680 - INFO -    Final Training Accuracy: 98.59%
2025-07-23 10:10:42,680 - INFO -  Analyzing model performance on validation set...
2025-07-23 10:10:43,156 - INFO - Confusion matrix saved to: training_plots/confusion_matrix.png
2025-07-23 10:10:49,595 - INFO - 
2025-07-23 10:10:49,595 - INFO - ============================================================
2025-07-23 10:10:49,595 - INFO - CLASSIFICATION REPORT
2025-07-23 10:10:49,595 - INFO - ============================================================
2025-07-23 10:10:49,599 - INFO -               precision    recall  f1-score   support
2025-07-23 10:10:49,599 - INFO - 
2025-07-23 10:10:49,599 - INFO -      Class_1       0.75      0.75      0.75         4
2025-07-23 10:10:49,599 - INFO -      Class_2       1.00      1.00      1.00         4
2025-07-23 10:10:49,599 - INFO -      Class_3       1.00      1.00      1.00         4
2025-07-23 10:10:49,599 - INFO -      Class_4       1.00      1.00      1.00         4
2025-07-23 10:10:49,599 - INFO -      Class_5       1.00      1.00      1.00         4
2025-07-23 10:10:49,599 - INFO -      Class_6       1.00      1.00      1.00         4
2025-07-23 10:10:49,599 - INFO -      Class_7       1.00      1.00      1.00         4
2025-07-23 10:10:49,600 - INFO -      Class_8       1.00      1.00      1.00         4
2025-07-23 10:10:49,600 - INFO -      Class_9       1.00      0.75      0.86         4
2025-07-23 10:10:49,600 - INFO -     Class_10       1.00      1.00      1.00         4
2025-07-23 10:10:49,600 - INFO -     Class_11       1.00      1.00      1.00         4
2025-07-23 10:10:49,600 - INFO -     Class_12       0.60      0.75      0.67         4
2025-07-23 10:10:49,600 - INFO -     Class_13       1.00      1.00      1.00         4
2025-07-23 10:10:49,600 - INFO -     Class_14       1.00      1.00      1.00         4
2025-07-23 10:10:49,600 - INFO -     Class_15       1.00      1.00      1.00         4
2025-07-23 10:10:49,600 - INFO - 
2025-07-23 10:10:49,600 - INFO -     accuracy                           0.95        60
2025-07-23 10:10:49,600 - INFO -    macro avg       0.96      0.95      0.95        60
2025-07-23 10:10:49,600 - INFO - weighted avg       0.96      0.95      0.95        60
2025-07-23 10:10:49,600 - INFO - 
2025-07-23 10:10:49,600 - INFO - ================================================================================
2025-07-23 10:10:49,600 - INFO - üéâ TRAINING COMPLETED SUCCESSFULLY!
2025-07-23 10:10:49,600 - INFO - ================================================================================
2025-07-23 10:10:49,600 - INFO - üèÜ Best validation accuracy: 95.00%
2025-07-23 10:10:49,600 - INFO - üíæ Model saved to: outputs/models/best_hgc_lstm.pth
2025-07-23 10:10:49,600 - INFO - üìä Plots saved to: outputs/plots
2025-07-23 10:10:49,600 - INFO - üìù Training log saved to: /home/na/VSLR/outputs/logs/training_20250723_100519.log
2025-07-23 10:10:49,600 - INFO - üìÖ End time: 2025-07-23 10:10:49
2025-07-23 10:10:49,601 - INFO - ================================================================================
