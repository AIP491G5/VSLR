2025-07-30 10:12:49,025 - INFO - ================================================================================
2025-07-30 10:12:49,025 - INFO - üöÄ VSLR Training Started
2025-07-30 10:12:49,025 - INFO - ================================================================================
2025-07-30 10:12:49,025 - INFO - üìù Log file: /home/na/VSLR/outputs/logs/training_20250730_101249.log
2025-07-30 10:12:49,025 - INFO - üìÖ Start time: 2025-07-30 10:12:49
2025-07-30 10:12:49,082 - INFO - Using device: cuda
2025-07-30 10:12:49,083 - INFO - Configuration loaded
2025-07-30 10:12:49,083 - INFO - Loading labels...
2025-07-30 10:12:49,086 - INFO - 
2025-07-30 10:12:49,086 - INFO -  Creating datasets...
2025-07-30 10:12:49,086 - INFO - Configuration:
2025-07-30 10:12:49,086 - INFO -    Split strategy: Stratified
2025-07-30 10:12:49,086 - INFO -    Train augmentations: ['translation', 'scaling']
2025-07-30 10:12:49,086 - INFO -    Val augmentations: None (for fair evaluation)
2025-07-30 10:12:49,086 - INFO -    Translation range: ¬±0.1
2025-07-30 10:12:49,086 - INFO -    Scale range: ¬±0.1
2025-07-30 10:12:49,087 - INFO -  Using stratified split strategy
2025-07-30 10:12:49,087 - INFO -  TRAIN dataset: 270 original files
2025-07-30 10:12:49,087 - INFO -  Augmentation enabled: 1080 total samples (x4)
2025-07-30 10:12:49,087 - INFO -   - Augmentations: ['translation', 'scaling']
2025-07-30 10:12:49,087 - INFO -   - Total combinations: 4
2025-07-30 10:12:49,087 - INFO -   - Combinations: ['original', 'translation', 'scaling', 'translation+scaling']
2025-07-30 10:12:49,087 - INFO -  TRAIN class distribution:
2025-07-30 10:12:49,087 - INFO -   Class 1: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 2: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 3: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 4: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 5: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 6: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 7: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 8: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 9: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 10: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 11: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 12: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 13: 18 samples
2025-07-30 10:12:49,087 - INFO -   Class 14: 18 samples
2025-07-30 10:12:49,088 - INFO -   Class 15: 18 samples
2025-07-30 10:12:49,088 - INFO -  ‚úì Balanced: 18 samples per class
2025-07-30 10:12:49,088 - INFO -  Using stratified split strategy
2025-07-30 10:12:49,088 - INFO -  VAL dataset: 30 original files
2025-07-30 10:12:49,088 - INFO -  No augmentation enabled: 30 total samples
2025-07-30 10:12:49,088 - INFO -  VAL class distribution:
2025-07-30 10:12:49,088 - INFO -   Class 1: 2 samples
2025-07-30 10:12:49,088 - INFO -   Class 2: 2 samples
2025-07-30 10:12:49,088 - INFO -   Class 3: 2 samples
2025-07-30 10:12:49,088 - INFO -   Class 4: 2 samples
2025-07-30 10:12:49,088 - INFO -   Class 5: 2 samples
2025-07-30 10:12:49,088 - INFO -   Class 6: 2 samples
2025-07-30 10:12:49,088 - INFO -   Class 7: 2 samples
2025-07-30 10:12:49,088 - INFO -   Class 8: 2 samples
2025-07-30 10:12:49,089 - INFO -   Class 9: 2 samples
2025-07-30 10:12:49,089 - INFO -   Class 10: 2 samples
2025-07-30 10:12:49,089 - INFO -   Class 11: 2 samples
2025-07-30 10:12:49,089 - INFO -   Class 12: 2 samples
2025-07-30 10:12:49,089 - INFO -   Class 13: 2 samples
2025-07-30 10:12:49,089 - INFO -   Class 14: 2 samples
2025-07-30 10:12:49,089 - INFO -   Class 15: 2 samples
2025-07-30 10:12:49,089 - INFO -  ‚úì Balanced: 2 samples per class
2025-07-30 10:12:49,089 - INFO - 
2025-07-30 10:12:49,089 - INFO - Dataset summary:
2025-07-30 10:12:49,089 - INFO -   Total classes: 15
2025-07-30 10:12:49,089 - INFO -   Train samples: 1080
2025-07-30 10:12:49,089 - INFO -   Val samples: 30
2025-07-30 10:12:49,089 - INFO -   Strategy: Stratified split
2025-07-30 10:12:49,089 - INFO - 
2025-07-30 10:12:49,089 - INFO - Creating data loaders...
2025-07-30 10:12:49,089 - INFO -  Train batches: 135
2025-07-30 10:12:49,090 - INFO -  Valid batches: 4
2025-07-30 10:12:49,090 - INFO -  Batch size: 8
2025-07-30 10:12:49,090 - INFO -  Data Augmentation (translation + scaling): 270 original ‚Üí 1080 total samples
2025-07-30 10:12:49,090 - INFO -  Augmentation combinations: ['original', 'translation', 'scaling', 'translation+scaling']
2025-07-30 10:12:49,117 - INFO -  Sample keypoints shape: torch.Size([8, 60, 75, 2])
2025-07-30 10:12:49,117 - INFO -  Sample labels shape: torch.Size([8])
2025-07-30 10:12:49,117 - INFO - 
2025-07-30 10:12:49,117 - INFO - Creating adjacency matrix...
2025-07-30 10:12:49,118 - INFO -  Adjacency matrix shape: torch.Size([75, 75])
2025-07-30 10:12:49,118 - INFO -  Number of vertices: 75
2025-07-30 10:12:49,118 - INFO - 
2025-07-30 10:12:49,118 - INFO - Creating model...
2025-07-30 10:12:49,443 - INFO - Model created with 277393 parameters
2025-07-30 10:12:49,443 - INFO - 
2025-07-30 10:12:49,443 - INFO - Starting training...
2025-07-30 10:12:49,443 - INFO -  Training configuration:
2025-07-30 10:12:49,443 - INFO -   - Epochs: 300
2025-07-30 10:12:49,443 - INFO -   - Batch size: 8
2025-07-30 10:12:49,443 - INFO -   - Learning rate: 0.001
2025-07-30 10:12:49,443 - INFO -   - Optimizer: adam
2025-07-30 10:12:49,443 - INFO -   - Scheduler: step
2025-07-30 10:12:49,443 - INFO -   - Early stopping patience: 50
2025-07-30 10:12:52,159 - INFO - Epoch 001/300 | Train Loss: 2.2453 Acc: 22.13% | Val Loss: 1.6258 Acc: 43.33% | LR: 0.00100000
2025-07-30 10:12:53,246 - INFO - Epoch 002/300 | Train Loss: 1.7915 Acc: 37.69% | Val Loss: 1.2929 Acc: 46.67% | LR: 0.00100000
2025-07-30 10:12:54,310 - INFO - Epoch 003/300 | Train Loss: 1.5672 Acc: 44.26% | Val Loss: 1.1133 Acc: 66.67% | LR: 0.00100000
2025-07-30 10:12:55,373 - INFO - Epoch 004/300 | Train Loss: 1.4584 Acc: 49.44% | Val Loss: 0.9606 Acc: 63.33% | LR: 0.00100000
2025-07-30 10:12:56,441 - INFO - Epoch 005/300 | Train Loss: 1.2845 Acc: 54.17% | Val Loss: 0.8617 Acc: 66.67% | LR: 0.00100000
2025-07-30 10:12:57,516 - INFO - Epoch 006/300 | Train Loss: 1.1649 Acc: 58.61% | Val Loss: 0.8507 Acc: 70.00% | LR: 0.00100000
2025-07-30 10:12:58,627 - INFO - Epoch 007/300 | Train Loss: 1.0378 Acc: 62.87% | Val Loss: 0.6358 Acc: 83.33% | LR: 0.00100000
2025-07-30 10:12:59,560 - INFO - Epoch 008/300 | Train Loss: 0.9496 Acc: 66.48% | Val Loss: 0.6248 Acc: 80.00% | LR: 0.00100000
2025-07-30 10:13:00,501 - INFO - Epoch 009/300 | Train Loss: 0.8486 Acc: 71.39% | Val Loss: 0.6737 Acc: 80.00% | LR: 0.00100000
2025-07-30 10:13:01,437 - INFO - Epoch 010/300 | Train Loss: 0.7842 Acc: 73.24% | Val Loss: 0.5510 Acc: 90.00% | LR: 0.00100000
2025-07-30 10:13:02,383 - INFO - Epoch 011/300 | Train Loss: 0.6816 Acc: 76.39% | Val Loss: 0.5036 Acc: 83.33% | LR: 0.00100000
2025-07-30 10:13:03,438 - INFO - Epoch 012/300 | Train Loss: 0.6906 Acc: 77.69% | Val Loss: 0.3364 Acc: 86.67% | LR: 0.00100000
2025-07-30 10:13:04,533 - INFO - Epoch 013/300 | Train Loss: 0.6185 Acc: 79.07% | Val Loss: 0.3177 Acc: 86.67% | LR: 0.00100000
2025-07-30 10:13:05,636 - INFO - Epoch 014/300 | Train Loss: 0.5617 Acc: 80.65% | Val Loss: 0.3921 Acc: 86.67% | LR: 0.00100000
2025-07-30 10:13:06,741 - INFO - Epoch 015/300 | Train Loss: 0.5496 Acc: 79.44% | Val Loss: 0.4361 Acc: 86.67% | LR: 0.00100000
2025-07-30 10:13:07,841 - INFO - Epoch 016/300 | Train Loss: 0.5372 Acc: 83.06% | Val Loss: 0.4035 Acc: 86.67% | LR: 0.00100000
2025-07-30 10:13:08,937 - INFO - Epoch 017/300 | Train Loss: 0.4842 Acc: 83.80% | Val Loss: 0.4031 Acc: 90.00% | LR: 0.00100000
2025-07-30 10:13:10,034 - INFO - Epoch 018/300 | Train Loss: 0.3943 Acc: 87.87% | Val Loss: 0.3158 Acc: 86.67% | LR: 0.00100000
2025-07-30 10:13:11,134 - INFO - Epoch 019/300 | Train Loss: 0.3903 Acc: 87.96% | Val Loss: 0.4929 Acc: 76.67% | LR: 0.00100000
2025-07-30 10:13:12,234 - INFO - Epoch 020/300 | Train Loss: 0.3458 Acc: 89.26% | Val Loss: 0.3910 Acc: 86.67% | LR: 0.00050000
2025-07-30 10:13:13,339 - INFO - Epoch 021/300 | Train Loss: 0.3108 Acc: 90.74% | Val Loss: 0.1425 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:14,440 - INFO - Epoch 022/300 | Train Loss: 0.2087 Acc: 93.33% | Val Loss: 0.3240 Acc: 86.67% | LR: 0.00050000
2025-07-30 10:13:15,596 - INFO - Epoch 023/300 | Train Loss: 0.2043 Acc: 93.98% | Val Loss: 0.4150 Acc: 86.67% | LR: 0.00050000
2025-07-30 10:13:16,723 - INFO - Epoch 024/300 | Train Loss: 0.2071 Acc: 94.07% | Val Loss: 0.2834 Acc: 90.00% | LR: 0.00050000
2025-07-30 10:13:17,959 - INFO - Epoch 025/300 | Train Loss: 0.1937 Acc: 94.17% | Val Loss: 0.2827 Acc: 90.00% | LR: 0.00050000
2025-07-30 10:13:19,126 - INFO - Epoch 026/300 | Train Loss: 0.1732 Acc: 95.65% | Val Loss: 0.2865 Acc: 90.00% | LR: 0.00050000
2025-07-30 10:13:20,233 - INFO - Epoch 027/300 | Train Loss: 0.1534 Acc: 96.20% | Val Loss: 0.3223 Acc: 90.00% | LR: 0.00050000
2025-07-30 10:13:21,336 - INFO - Epoch 028/300 | Train Loss: 0.1061 Acc: 97.13% | Val Loss: 0.3270 Acc: 90.00% | LR: 0.00050000
2025-07-30 10:13:22,441 - INFO - Epoch 029/300 | Train Loss: 0.1224 Acc: 96.39% | Val Loss: 0.2508 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:23,427 - INFO - Epoch 030/300 | Train Loss: 0.1208 Acc: 96.39% | Val Loss: 0.2260 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:24,539 - INFO - Epoch 031/300 | Train Loss: 0.1213 Acc: 96.85% | Val Loss: 0.1949 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:25,665 - INFO - Epoch 032/300 | Train Loss: 0.0888 Acc: 98.06% | Val Loss: 0.2051 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:26,786 - INFO - Epoch 033/300 | Train Loss: 0.1308 Acc: 96.20% | Val Loss: 0.1793 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:27,887 - INFO - Epoch 034/300 | Train Loss: 0.1263 Acc: 96.20% | Val Loss: 0.2206 Acc: 90.00% | LR: 0.00050000
2025-07-30 10:13:28,878 - INFO - Epoch 035/300 | Train Loss: 0.0817 Acc: 97.50% | Val Loss: 0.2465 Acc: 86.67% | LR: 0.00050000
2025-07-30 10:13:29,831 - INFO - Epoch 036/300 | Train Loss: 0.0861 Acc: 97.41% | Val Loss: 0.2425 Acc: 90.00% | LR: 0.00050000
2025-07-30 10:13:30,776 - INFO - Epoch 037/300 | Train Loss: 0.1385 Acc: 96.20% | Val Loss: 0.1414 Acc: 96.67% | LR: 0.00050000
2025-07-30 10:13:31,753 - INFO - Epoch 038/300 | Train Loss: 0.0980 Acc: 96.76% | Val Loss: 0.2385 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:32,717 - INFO - Epoch 039/300 | Train Loss: 0.1064 Acc: 96.57% | Val Loss: 0.1136 Acc: 93.33% | LR: 0.00050000
2025-07-30 10:13:33,660 - INFO - Epoch 040/300 | Train Loss: 0.0983 Acc: 97.41% | Val Loss: 0.2036 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:34,594 - INFO - Epoch 041/300 | Train Loss: 0.0859 Acc: 98.15% | Val Loss: 0.2821 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:35,523 - INFO - Epoch 042/300 | Train Loss: 0.0485 Acc: 98.33% | Val Loss: 0.3358 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:36,457 - INFO - Epoch 043/300 | Train Loss: 0.0381 Acc: 98.98% | Val Loss: 0.3764 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:37,394 - INFO - Epoch 044/300 | Train Loss: 0.0437 Acc: 98.43% | Val Loss: 0.3646 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:38,342 - INFO - Epoch 045/300 | Train Loss: 0.0232 Acc: 99.54% | Val Loss: 0.4328 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:39,273 - INFO - Epoch 046/300 | Train Loss: 0.0371 Acc: 98.89% | Val Loss: 0.4033 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:40,221 - INFO - Epoch 047/300 | Train Loss: 0.0340 Acc: 99.17% | Val Loss: 0.3409 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:41,176 - INFO - Epoch 048/300 | Train Loss: 0.0370 Acc: 98.98% | Val Loss: 0.2840 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:42,111 - INFO - Epoch 049/300 | Train Loss: 0.0344 Acc: 98.61% | Val Loss: 0.3605 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:43,052 - INFO - Epoch 050/300 | Train Loss: 0.0292 Acc: 99.17% | Val Loss: 0.2223 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:43,990 - INFO - Epoch 051/300 | Train Loss: 0.0481 Acc: 98.70% | Val Loss: 0.1933 Acc: 93.33% | LR: 0.00025000
2025-07-30 10:13:44,915 - INFO - Epoch 052/300 | Train Loss: 0.0430 Acc: 98.98% | Val Loss: 0.2410 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:45,851 - INFO - Epoch 053/300 | Train Loss: 0.0415 Acc: 98.98% | Val Loss: 0.3471 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:46,785 - INFO - Epoch 054/300 | Train Loss: 0.0283 Acc: 99.44% | Val Loss: 0.1742 Acc: 93.33% | LR: 0.00025000
2025-07-30 10:13:47,717 - INFO - Epoch 055/300 | Train Loss: 0.0364 Acc: 99.26% | Val Loss: 0.2956 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:48,648 - INFO - Epoch 056/300 | Train Loss: 0.0615 Acc: 98.43% | Val Loss: 0.1523 Acc: 93.33% | LR: 0.00025000
2025-07-30 10:13:49,579 - INFO - Epoch 057/300 | Train Loss: 0.0374 Acc: 98.61% | Val Loss: 0.2612 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:50,512 - INFO - Epoch 058/300 | Train Loss: 0.0471 Acc: 98.61% | Val Loss: 0.1642 Acc: 93.33% | LR: 0.00025000
2025-07-30 10:13:51,443 - INFO - Epoch 059/300 | Train Loss: 0.0289 Acc: 99.26% | Val Loss: 0.2150 Acc: 90.00% | LR: 0.00025000
2025-07-30 10:13:52,380 - INFO - Epoch 060/300 | Train Loss: 0.0395 Acc: 99.07% | Val Loss: 0.2568 Acc: 93.33% | LR: 0.00012500
2025-07-30 10:13:53,310 - INFO - Epoch 061/300 | Train Loss: 0.0194 Acc: 99.35% | Val Loss: 0.1621 Acc: 93.33% | LR: 0.00012500
2025-07-30 10:13:54,263 - INFO - Epoch 062/300 | Train Loss: 0.0262 Acc: 99.35% | Val Loss: 0.2935 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:13:55,287 - INFO - Epoch 063/300 | Train Loss: 0.0357 Acc: 99.07% | Val Loss: 0.2494 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:13:56,232 - INFO - Epoch 064/300 | Train Loss: 0.0189 Acc: 99.54% | Val Loss: 0.2161 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:13:57,162 - INFO - Epoch 065/300 | Train Loss: 0.0168 Acc: 99.72% | Val Loss: 0.2101 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:13:58,108 - INFO - Epoch 066/300 | Train Loss: 0.0192 Acc: 99.44% | Val Loss: 0.2384 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:13:59,045 - INFO - Epoch 067/300 | Train Loss: 0.0259 Acc: 99.54% | Val Loss: 0.2660 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:13:59,984 - INFO - Epoch 068/300 | Train Loss: 0.0180 Acc: 99.44% | Val Loss: 0.3078 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:00,929 - INFO - Epoch 069/300 | Train Loss: 0.0109 Acc: 99.72% | Val Loss: 0.2868 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:01,854 - INFO - Epoch 070/300 | Train Loss: 0.0180 Acc: 99.72% | Val Loss: 0.2867 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:02,781 - INFO - Epoch 071/300 | Train Loss: 0.0248 Acc: 99.63% | Val Loss: 0.3716 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:03,710 - INFO - Epoch 072/300 | Train Loss: 0.0216 Acc: 99.17% | Val Loss: 0.3393 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:04,642 - INFO - Epoch 073/300 | Train Loss: 0.0147 Acc: 99.63% | Val Loss: 0.3067 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:05,574 - INFO - Epoch 074/300 | Train Loss: 0.0310 Acc: 99.44% | Val Loss: 0.2914 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:06,520 - INFO - Epoch 075/300 | Train Loss: 0.0244 Acc: 99.26% | Val Loss: 0.4239 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:07,456 - INFO - Epoch 076/300 | Train Loss: 0.0119 Acc: 99.54% | Val Loss: 0.1492 Acc: 93.33% | LR: 0.00012500
2025-07-30 10:14:08,390 - INFO - Epoch 077/300 | Train Loss: 0.0166 Acc: 99.63% | Val Loss: 0.1733 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:09,322 - INFO - Epoch 078/300 | Train Loss: 0.0195 Acc: 99.54% | Val Loss: 0.1591 Acc: 93.33% | LR: 0.00012500
2025-07-30 10:14:10,255 - INFO - Epoch 079/300 | Train Loss: 0.0114 Acc: 99.72% | Val Loss: 0.2158 Acc: 90.00% | LR: 0.00012500
2025-07-30 10:14:11,242 - INFO - Epoch 080/300 | Train Loss: 0.0330 Acc: 99.26% | Val Loss: 0.3617 Acc: 90.00% | LR: 0.00006250
2025-07-30 10:14:12,298 - INFO - Epoch 081/300 | Train Loss: 0.0214 Acc: 99.44% | Val Loss: 0.2859 Acc: 90.00% | LR: 0.00006250
2025-07-30 10:14:13,299 - INFO - Epoch 082/300 | Train Loss: 0.0089 Acc: 99.81% | Val Loss: 0.2963 Acc: 90.00% | LR: 0.00006250
2025-07-30 10:14:14,244 - INFO - Epoch 083/300 | Train Loss: 0.0061 Acc: 99.91% | Val Loss: 0.2549 Acc: 93.33% | LR: 0.00006250
2025-07-30 10:14:15,192 - INFO - Epoch 084/300 | Train Loss: 0.0060 Acc: 99.91% | Val Loss: 0.3032 Acc: 90.00% | LR: 0.00006250
2025-07-30 10:14:16,116 - INFO - Epoch 085/300 | Train Loss: 0.0077 Acc: 99.81% | Val Loss: 0.3041 Acc: 93.33% | LR: 0.00006250
2025-07-30 10:14:17,044 - INFO - Epoch 086/300 | Train Loss: 0.0064 Acc: 99.81% | Val Loss: 0.3267 Acc: 90.00% | LR: 0.00006250
2025-07-30 10:14:17,991 - INFO - Epoch 087/300 | Train Loss: 0.0056 Acc: 99.91% | Val Loss: 0.2334 Acc: 90.00% | LR: 0.00006250
2025-07-30 10:14:17,991 - INFO - Early stopping triggered after 87 epochs
2025-07-30 10:14:17,991 - INFO - Training completed. Best validation accuracy: 96.67% (Train: 96.20%)
2025-07-30 10:14:17,991 - INFO - 
2025-07-30 10:14:17,991 - INFO - Generating training visualizations...
2025-07-30 10:14:17,991 - INFO - Loading best model from: outputs/models/best_hgc_lstm.pth
2025-07-30 10:14:18,600 - INFO - Training curves saved to: training_plots/training_curves.png
2025-07-30 10:16:27,135 - INFO - 
2025-07-30 10:16:27,136 - INFO - üìä TRAINING SUMMARY:
2025-07-30 10:16:27,136 - INFO -    Best Validation Accuracy: 96.67% (Epoch 37)
2025-07-30 10:16:27,136 - INFO -    Final Training Accuracy: 99.91%
2025-07-30 10:16:27,136 - INFO -  Analyzing model performance on validation set...
2025-07-30 10:16:27,682 - INFO - Confusion matrix saved to: training_plots/confusion_matrix.png
2025-07-30 10:16:30,352 - INFO - 
2025-07-30 10:16:30,353 - INFO - ============================================================
2025-07-30 10:16:30,353 - INFO - CLASSIFICATION REPORT
2025-07-30 10:16:30,353 - INFO - ============================================================
2025-07-30 10:16:30,357 - INFO -               precision    recall  f1-score   support
2025-07-30 10:16:30,357 - INFO - 
2025-07-30 10:16:30,357 - INFO -      Class_1       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_2       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_3       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_4       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_5       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_6       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_7       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_8       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -      Class_9       1.00      0.50      0.67         2
2025-07-30 10:16:30,357 - INFO -     Class_10       0.67      1.00      0.80         2
2025-07-30 10:16:30,357 - INFO -     Class_11       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -     Class_12       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -     Class_13       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -     Class_14       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO -     Class_15       1.00      1.00      1.00         2
2025-07-30 10:16:30,357 - INFO - 
2025-07-30 10:16:30,358 - INFO -     accuracy                           0.97        30
2025-07-30 10:16:30,358 - INFO -    macro avg       0.98      0.97      0.96        30
2025-07-30 10:16:30,358 - INFO - weighted avg       0.98      0.97      0.96        30
2025-07-30 10:16:30,358 - INFO - 
2025-07-30 10:16:30,358 - INFO - ================================================================================
2025-07-30 10:16:30,358 - INFO - üéâ TRAINING COMPLETED SUCCESSFULLY!
2025-07-30 10:16:30,358 - INFO - ================================================================================
2025-07-30 10:16:30,358 - INFO - üèÜ Best validation accuracy: 96.67%
2025-07-30 10:16:30,358 - INFO - üíæ Model saved to: outputs/models/best_hgc_lstm.pth
2025-07-30 10:16:30,358 - INFO - üìä Plots saved to: outputs/plots
2025-07-30 10:16:30,358 - INFO - üìù Training log saved to: /home/na/VSLR/outputs/logs/training_20250730_101249.log
2025-07-30 10:16:30,358 - INFO - üìÖ End time: 2025-07-30 10:16:30
2025-07-30 10:16:30,358 - INFO - ================================================================================
